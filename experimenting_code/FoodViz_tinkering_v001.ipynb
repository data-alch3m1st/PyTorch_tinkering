{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "_lijMVhtflyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qF7sI6lif5kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from the drive:\n",
        "\n",
        "train_dir = \"/content/drive/MyDrive/_Δατα_sсιεисэ/PyTorch_experimenting/data/pizza_steak_sushi\"\n",
        "test_dir = \"/content/drive/MyDrive/_Δατα_sсιεисэ/PyTorch_experimenting/data/pizza_steak_sushi\""
      ],
      "metadata": {
        "id": "dXZ65pYgfxg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgbS43UEVzEf",
        "outputId": "64040e3a-2df9-47d9-8c4d-f670c629b2c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 208MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Load ResNet50 with V2 pretrained weights\n",
        "weights_v2 = models.ResNet50_Weights.IMAGENET1K_V2\n",
        "model_v2 = models.resnet50(weights=weights_v2)\n",
        "\n",
        "# Get the preprocessing transforms associated with these weights\n",
        "preprocess_v2 = weights_v2.transforms()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResnetV2 ###"
      ],
      "metadata": {
        "id": "-BMAa5bLeB_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the preprocessing from ResNet50 V2 for this example\n",
        "# (If you switch models, swap preprocess_v2 for the other variant.)\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root=train_dir\n",
        "    , transform=preprocess_v2\n",
        ")\n",
        "\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    root=test_dir\n",
        "    , transform=preprocess_v2\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset\n",
        "    , batch_size=32\n",
        "    , shuffle=True\n",
        "    , num_workers=2\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset\n",
        "    , batch_size=32\n",
        "    , shuffle=False\n",
        "    , num_workers=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "ByZG3e5pV9lQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNetV2 Model, class, device, criterion & optimizer instantiation;\n",
        "\n",
        "# Number of classes in Pizza–Steak–Sushi\n",
        "num_classes = len(train_dataset.classes)  # should be 3\n",
        "\n",
        "# Use ResNet50 V2 backbone\n",
        "model = model_v2\n",
        "\n",
        "# Freeze all layers except the final classifier head\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the final fully connected layer (ResNet50 uses model.fc)\n",
        "model.fc = nn.Linear(\n",
        "      in_features=model.fc.in_features\n",
        "      , out_features=num_classes\n",
        ")\n",
        "\n",
        "# Move to device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss & optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(\n",
        "      model.fc.parameters()\n",
        "      , lr=1e-3\n",
        ")"
      ],
      "metadata": {
        "id": "5_RqiykFV9oP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNetV2 Training Loop\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += torch.sum(preds == labels).item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / total\n",
        "    train_acc = correct / total * 100\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {train_loss:.4f} | Acc: {train_acc:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfDo3R8iV9wG",
        "outputId": "2f6e99b8-60af-4bd0-a4e5-6a5c224c255e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Loss: 0.6090 | Acc: 70.6667%\n",
            "Epoch 2/5 | Loss: 0.5499 | Acc: 75.0000%\n",
            "Epoch 3/5 | Loss: 0.5137 | Acc: 75.3333%\n",
            "Epoch 4/5 | Loss: 0.4703 | Acc: 75.0000%\n",
            "Epoch 5/5 | Loss: 0.4465 | Acc: 75.0000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResnetV1 ###"
      ],
      "metadata": {
        "id": "O6_z_1Jwd0oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ResNet50 with V1 pretrained weights\n",
        "\n",
        "weights_v1 = models.ResNet50_Weights.IMAGENET1K_V1\n",
        "model_v1 = models.resnet50(weights=weights_v1)\n",
        "preprocess_v1 = weights_v1.transforms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC3JDj9GV9Y9",
        "outputId": "7f011f89-2333-4bae-82ee-1b0d0776caa7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 160MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNetV1 --> need to use preprocess_v1 transform!\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root=train_dir\n",
        "    , transform=preprocess_v1\n",
        ")\n",
        "\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    root=test_dir\n",
        "    , transform=preprocess_v1\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset\n",
        "    , batch_size=32\n",
        "    , shuffle=True\n",
        "    , num_workers=2\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset\n",
        "    , batch_size=32\n",
        "    , shuffle=False\n",
        "    , num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "1FOroXiJcHvr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNetV1 Model, class, device, criterion & optimizer instantiation;\n",
        "\n",
        "# Number of classes in Pizza–Steak–Sushi\n",
        "num_classes = len(train_dataset.classes)  # should be 3\n",
        "\n",
        "# Use ResNet50 V1 backbone\n",
        "model = model_v1\n",
        "\n",
        "# Freeze all layers except the final classifier head\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the final fully connected layer (ResNet50 uses model.fc)\n",
        "model.fc = nn.Linear(\n",
        "      in_features=model.fc.in_features\n",
        "    , out_features=num_classes\n",
        ")\n",
        "\n",
        "# Move to device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss & optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(\n",
        "      model.fc.parameters()\n",
        "      , lr=1e-3\n",
        ")"
      ],
      "metadata": {
        "id": "-rrpuLfYV9zP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNetV1 Training Loop\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += torch.sum(preds == labels).item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / total\n",
        "    train_acc = correct / total * 100\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {train_loss:.4f} | Acc: {train_acc:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYRuv23rX1pZ",
        "outputId": "38cfdb8f-d7f0-42ed-e51b-d3b74a00bdca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Loss: 0.7194 | Acc: 60.6667%\n",
            "Epoch 2/5 | Loss: 0.5501 | Acc: 74.6667%\n",
            "Epoch 3/5 | Loss: 0.5522 | Acc: 75.6667%\n",
            "Epoch 4/5 | Loss: 0.5638 | Acc: 77.3333%\n",
            "Epoch 5/5 | Loss: 0.5075 | Acc: 76.6667%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EfficientNet_B0 ###"
      ],
      "metadata": {
        "id": "IWc7_ZxbeJe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load EfficientNet with B0 pretrained weights\n",
        "\n",
        "weights_eff = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
        "model_eff = models.efficientnet_b0(weights=weights_eff)\n",
        "preprocess_eff = weights_eff.transforms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsR43MxPV9eZ",
        "outputId": "e20b65cc-31b6-4b18-f703-3859d2f01305"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 171MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the preprocess transform for EfficientNet_B0 (preprocess_eff)\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root=train_dir\n",
        "    , transform=preprocess_eff\n",
        ")\n",
        "\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    root=test_dir\n",
        "    , transform=preprocess_eff\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset\n",
        "    , batch_size=32\n",
        "    , shuffle=True\n",
        "    , num_workers=2\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset\n",
        "    , batch_size=32\n",
        "    , shuffle=False\n",
        "    , num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "hpm8c2VLcYap"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Number of classes in Pizza–Steak–Sushi\n",
        "num_classes = len(train_dataset.classes)  # should be 3\n",
        "\n",
        "# Use ResNet50 V1 backbone\n",
        "model = model_eff\n",
        "\n",
        "# Freeze all layers except the final classifier head\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the final layer --> EfficientNet uses model.classifier\n",
        "model.classifier = nn.Linear(\n",
        "      in_features=model.classifier[1].in_features\n",
        "      , out_features=num_classes\n",
        ")\n",
        "\n",
        "# Move to device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss & optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(\n",
        "      model.classifier.parameters()\n",
        "      , lr=1e-3\n",
        ")"
      ],
      "metadata": {
        "id": "cNnx9Zf2cYaq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EfficientNet_B0 Training Loop\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += torch.sum(preds == labels).item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / total\n",
        "    train_acc = correct / total * 100\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {train_loss:.4f} | Acc: {train_acc:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c68465e1-aaee-4279-c4b6-4cec62ed1a34",
        "id": "U46_MwK1cYaq"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Loss: 0.6044 | Acc: 71.6667%\n",
            "Epoch 2/5 | Loss: 0.5457 | Acc: 74.6667%\n",
            "Epoch 3/5 | Loss: 0.5142 | Acc: 78.0000%\n",
            "Epoch 4/5 | Loss: 0.4865 | Acc: 78.0000%\n",
            "Epoch 5/5 | Loss: 0.4642 | Acc: 78.0000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ^^^ It looks like EfficientNet did better on the train loop, so running some more epochs to see if the acc scores can get higher! (Note: ended up re-running another 10 epochs, so 25 epochs in total, w/ 93.333% max acc;)\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += torch.sum(preds == labels).item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / total\n",
        "    train_acc = correct / total * 100\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {train_loss:.4f} | Acc: {train_acc:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ARWAXKHX1wp",
        "outputId": "5f4723bb-155a-47b5-d94f-f949dc2bb3fe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.3263 | Acc: 87.3333%\n",
            "Epoch 2/10 | Loss: 0.3091 | Acc: 89.6667%\n",
            "Epoch 3/10 | Loss: 0.2974 | Acc: 92.0000%\n",
            "Epoch 4/10 | Loss: 0.3019 | Acc: 87.6667%\n",
            "Epoch 5/10 | Loss: 0.2821 | Acc: 91.3333%\n",
            "Epoch 6/10 | Loss: 0.2911 | Acc: 90.6667%\n",
            "Epoch 7/10 | Loss: 0.2710 | Acc: 91.0000%\n",
            "Epoch 8/10 | Loss: 0.2714 | Acc: 90.0000%\n",
            "Epoch 9/10 | Loss: 0.2674 | Acc: 91.0000%\n",
            "Epoch 10/10 | Loss: 0.2598 | Acc: 93.3333%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running Test Loop on EfficientNet\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += torch.sum(preds == labels).item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "test_acc = correct / total * 100\n",
        "print(f\"Test Accuracy: {test_acc:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh05aWKVV92V",
        "outputId": "a61f945c-1e8d-4bbb-eb15-a824f182889f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 99.0000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "You cannot directly use the Google Drive folder link as a file path in Colab. After you mount your Google Drive, you can navigate to the folder in the file browser on the left-hand side of Colab to find its path. It will likely be something like /content/drive/My Drive/Your Folder Name.\n",
        "\n",
        "Once you have the correct path, you can use it to load your data.\n",
        "\n",
        "/content/drive/MyDrive/_Δατα_sсιεисэ/PyTorch_experimenting/data/pizza_steak_sushi\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UYY5NOn6V9rq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}