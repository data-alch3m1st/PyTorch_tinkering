{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa7770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd6c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a0a78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15622418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7, 7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.tensor([7, 7, 7])\n",
    "t1\n",
    "t1.shape\n",
    "t1.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "686eccab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "matrix = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "matrix\n",
    "\n",
    "matrix.shape\n",
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bedae7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12],\n",
       "        [13, 14]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "matrix = torch.tensor([[7, 8], \n",
    "                       [9, 10],\n",
    "                       [11, 12],\n",
    "                       [13, 14]]\n",
    "                     )\n",
    "matrix\n",
    "\n",
    "matrix.shape\n",
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "853f74a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "TENSOR\n",
    "TENSOR.shape\n",
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ec9638b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "tensor3d\n",
    "tensor3d.shape\n",
    "tensor3d.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77556000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[[[9.2935e-01, 3.0501e-01, 5.3447e-01],\n",
       "            [5.2982e-01, 7.9489e-01, 9.7576e-01],\n",
       "            [6.2918e-01, 4.9524e-01, 4.9543e-02]],\n",
       "\n",
       "           [[6.6030e-01, 1.4775e-01, 2.3883e-01],\n",
       "            [1.0699e-01, 4.2705e-01, 4.0886e-01],\n",
       "            [6.4102e-01, 9.1255e-01, 3.9856e-01]],\n",
       "\n",
       "           [[7.3895e-01, 1.1687e-01, 5.3332e-01],\n",
       "            [1.4145e-01, 5.1904e-01, 2.8691e-01],\n",
       "            [5.5170e-01, 1.1683e-01, 9.2646e-01]]],\n",
       "\n",
       "\n",
       "          [[[4.4474e-01, 7.9244e-01, 5.4170e-01],\n",
       "            [3.2304e-01, 3.5352e-01, 8.2675e-01],\n",
       "            [4.3385e-01, 9.3523e-01, 8.0720e-01]],\n",
       "\n",
       "           [[5.8807e-01, 2.0272e-01, 7.1759e-01],\n",
       "            [5.5115e-01, 1.4014e-01, 9.2848e-01],\n",
       "            [6.2028e-01, 5.9632e-01, 7.9817e-04]],\n",
       "\n",
       "           [[3.0655e-01, 3.2131e-01, 6.2910e-01],\n",
       "            [6.0130e-01, 4.8475e-01, 2.1367e-01],\n",
       "            [2.9963e-01, 7.8837e-01, 7.6098e-01]]],\n",
       "\n",
       "\n",
       "          [[[4.7089e-01, 4.8823e-01, 5.4533e-01],\n",
       "            [2.7043e-01, 6.4770e-01, 4.1541e-01],\n",
       "            [4.8449e-01, 5.3934e-01, 6.9062e-01]],\n",
       "\n",
       "           [[4.3747e-01, 4.3791e-02, 2.2441e-01],\n",
       "            [4.7155e-01, 5.6932e-01, 3.8832e-01],\n",
       "            [2.4351e-01, 6.6060e-01, 9.1061e-01]],\n",
       "\n",
       "           [[1.2575e-01, 2.5044e-01, 7.3639e-01],\n",
       "            [6.6836e-01, 7.6015e-01, 1.7767e-01],\n",
       "            [5.2779e-01, 1.9312e-01, 5.8620e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[5.9628e-01, 6.7216e-01, 8.0743e-01],\n",
       "            [3.7896e-02, 2.5508e-01, 7.0029e-02],\n",
       "            [2.8794e-01, 9.0089e-01, 8.4462e-01]],\n",
       "\n",
       "           [[2.5287e-01, 2.6947e-01, 5.0499e-01],\n",
       "            [2.5165e-01, 7.8121e-02, 4.1882e-01],\n",
       "            [5.7058e-01, 3.8034e-01, 1.7307e-01]],\n",
       "\n",
       "           [[3.9016e-01, 7.2415e-02, 9.5166e-02],\n",
       "            [7.6479e-01, 8.1222e-01, 7.0540e-01],\n",
       "            [2.7220e-01, 3.8944e-01, 1.3770e-01]]],\n",
       "\n",
       "\n",
       "          [[[1.0373e-01, 9.0342e-01, 4.7019e-01],\n",
       "            [2.3668e-01, 2.5653e-01, 6.1558e-01],\n",
       "            [5.0541e-01, 2.9538e-01, 2.4225e-01]],\n",
       "\n",
       "           [[6.2896e-02, 5.8190e-01, 1.7981e-01],\n",
       "            [2.0751e-02, 1.6222e-01, 8.7251e-01],\n",
       "            [1.4143e-01, 3.6406e-01, 1.4172e-01]],\n",
       "\n",
       "           [[6.5248e-01, 4.7269e-01, 8.2144e-01],\n",
       "            [8.0880e-01, 5.4075e-01, 9.2219e-01],\n",
       "            [3.3848e-01, 7.6991e-01, 9.1648e-01]]],\n",
       "\n",
       "\n",
       "          [[[2.8546e-01, 4.8495e-01, 1.2897e-01],\n",
       "            [5.8498e-01, 7.5771e-01, 2.8402e-01],\n",
       "            [7.8970e-01, 1.7477e-01, 3.1265e-01]],\n",
       "\n",
       "           [[3.5197e-01, 2.8168e-01, 8.5396e-01],\n",
       "            [4.0443e-01, 7.2857e-01, 8.7391e-01],\n",
       "            [1.5058e-01, 3.1468e-01, 6.6680e-01]],\n",
       "\n",
       "           [[2.6093e-01, 3.9869e-01, 8.7695e-01],\n",
       "            [7.6205e-01, 5.5211e-01, 4.1379e-01],\n",
       "            [2.5208e-01, 3.0957e-02, 5.0563e-02]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[7.4161e-01, 4.3631e-01, 2.9971e-01],\n",
       "            [9.1050e-01, 4.2698e-01, 8.2631e-01],\n",
       "            [2.5697e-01, 8.7733e-01, 4.1214e-01]],\n",
       "\n",
       "           [[2.7925e-01, 1.0910e-01, 6.5487e-01],\n",
       "            [5.5045e-01, 4.6275e-03, 9.2044e-01],\n",
       "            [9.8917e-01, 3.8237e-01, 7.9160e-01]],\n",
       "\n",
       "           [[7.0333e-01, 6.9409e-01, 3.6633e-01],\n",
       "            [8.0310e-01, 6.3055e-01, 8.6292e-01],\n",
       "            [1.4886e-01, 5.7689e-01, 9.4971e-01]]],\n",
       "\n",
       "\n",
       "          [[[1.8626e-01, 9.1837e-01, 1.2921e-01],\n",
       "            [9.4280e-01, 8.2193e-02, 1.4781e-01],\n",
       "            [8.8797e-01, 4.3928e-01, 9.2787e-01]],\n",
       "\n",
       "           [[7.5933e-01, 4.9298e-01, 4.2604e-01],\n",
       "            [8.4974e-01, 4.7962e-02, 3.0031e-01],\n",
       "            [7.6484e-02, 3.4443e-01, 5.0659e-01]],\n",
       "\n",
       "           [[1.0245e-01, 6.3403e-01, 7.9452e-01],\n",
       "            [4.0379e-01, 8.2167e-01, 2.6615e-01],\n",
       "            [9.4405e-01, 8.9747e-01, 1.3415e-01]]],\n",
       "\n",
       "\n",
       "          [[[8.5351e-01, 5.2475e-01, 9.1840e-01],\n",
       "            [7.5289e-01, 8.1351e-01, 2.2330e-01],\n",
       "            [2.7862e-02, 9.3807e-01, 2.8372e-01]],\n",
       "\n",
       "           [[5.5212e-01, 4.1945e-01, 9.6927e-01],\n",
       "            [9.7221e-01, 8.4854e-01, 2.0623e-01],\n",
       "            [6.4275e-01, 1.6844e-01, 8.9390e-02]],\n",
       "\n",
       "           [[6.7629e-01, 9.2875e-01, 2.5897e-01],\n",
       "            [7.2068e-01, 3.3085e-01, 5.0139e-01],\n",
       "            [8.1719e-01, 9.6698e-01, 5.3069e-01]]]]],\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "        [[[[[6.3507e-01, 9.3599e-01, 8.8293e-01],\n",
       "            [5.8580e-01, 6.1440e-01, 8.6779e-01],\n",
       "            [3.3451e-01, 9.9617e-02, 1.2748e-01]],\n",
       "\n",
       "           [[8.7455e-01, 7.2870e-01, 5.4840e-01],\n",
       "            [7.0768e-02, 8.1590e-01, 5.8625e-01],\n",
       "            [3.0393e-01, 7.9989e-01, 4.9651e-02]],\n",
       "\n",
       "           [[5.1204e-01, 8.7957e-01, 5.8117e-01],\n",
       "            [2.4703e-01, 1.4936e-01, 5.2429e-01],\n",
       "            [2.6398e-01, 4.6855e-01, 5.5585e-01]]],\n",
       "\n",
       "\n",
       "          [[[3.5084e-01, 1.7588e-01, 7.5546e-01],\n",
       "            [3.5621e-01, 1.0196e-01, 1.9079e-01],\n",
       "            [2.2661e-01, 9.3772e-01, 5.7640e-01]],\n",
       "\n",
       "           [[4.2235e-01, 8.4939e-01, 3.5956e-02],\n",
       "            [4.5089e-02, 4.4719e-02, 7.6610e-01],\n",
       "            [7.9144e-01, 9.7842e-01, 8.4802e-01]],\n",
       "\n",
       "           [[8.8898e-02, 7.1573e-01, 1.8134e-02],\n",
       "            [8.7271e-01, 2.2941e-02, 9.8297e-01],\n",
       "            [8.9117e-01, 1.0010e-01, 1.3889e-01]]],\n",
       "\n",
       "\n",
       "          [[[6.2348e-01, 7.6488e-01, 8.6843e-01],\n",
       "            [1.9199e-01, 5.6500e-01, 3.4637e-01],\n",
       "            [4.3154e-01, 4.6739e-01, 6.7357e-01]],\n",
       "\n",
       "           [[7.5296e-01, 2.1924e-01, 2.2891e-01],\n",
       "            [4.9914e-01, 5.7722e-01, 4.2120e-01],\n",
       "            [4.5563e-01, 5.2998e-01, 3.9450e-01]],\n",
       "\n",
       "           [[9.5590e-01, 3.3527e-01, 6.6063e-02],\n",
       "            [9.5762e-01, 3.6718e-01, 9.7317e-01],\n",
       "            [2.8713e-01, 7.1204e-01, 2.6117e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[8.5592e-01, 3.9256e-01, 3.0356e-01],\n",
       "            [7.7418e-01, 4.5399e-01, 3.5090e-01],\n",
       "            [6.4353e-01, 3.3932e-01, 9.6657e-01]],\n",
       "\n",
       "           [[5.0057e-01, 7.3240e-01, 8.2892e-01],\n",
       "            [6.5700e-01, 9.5306e-01, 1.4452e-01],\n",
       "            [9.1558e-02, 2.5013e-01, 1.7164e-01]],\n",
       "\n",
       "           [[5.1837e-01, 6.3629e-01, 5.4797e-01],\n",
       "            [8.8300e-01, 1.8064e-01, 1.0726e-01],\n",
       "            [5.9811e-01, 7.1939e-01, 7.5103e-01]]],\n",
       "\n",
       "\n",
       "          [[[1.9091e-01, 8.0661e-02, 4.2631e-01],\n",
       "            [5.9174e-01, 8.1000e-01, 4.5350e-01],\n",
       "            [8.9391e-01, 8.9654e-01, 2.2865e-01]],\n",
       "\n",
       "           [[3.7196e-01, 1.5923e-01, 8.5182e-01],\n",
       "            [8.4446e-01, 4.4424e-01, 6.5335e-02],\n",
       "            [9.3132e-01, 3.8420e-02, 3.4163e-01]],\n",
       "\n",
       "           [[7.4612e-01, 1.3331e-01, 5.6160e-01],\n",
       "            [5.5778e-01, 5.2619e-01, 3.3241e-01],\n",
       "            [6.2158e-01, 4.9165e-01, 6.6490e-01]]],\n",
       "\n",
       "\n",
       "          [[[3.7567e-01, 1.3700e-01, 1.4110e-01],\n",
       "            [5.6342e-02, 5.9901e-01, 4.3782e-01],\n",
       "            [6.9949e-01, 6.9104e-01, 2.4219e-01]],\n",
       "\n",
       "           [[6.1227e-02, 9.8250e-01, 3.4894e-01],\n",
       "            [1.9296e-01, 2.4237e-01, 8.6165e-01],\n",
       "            [2.2110e-01, 5.5419e-01, 6.7894e-01]],\n",
       "\n",
       "           [[8.8516e-02, 9.3205e-01, 1.2212e-01],\n",
       "            [3.3404e-01, 9.2021e-01, 4.5578e-02],\n",
       "            [5.0347e-01, 8.3350e-01, 9.0830e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[1.2403e-01, 9.3000e-01, 1.3082e-01],\n",
       "            [5.3402e-01, 3.7215e-01, 6.4057e-01],\n",
       "            [3.7516e-01, 5.4421e-02, 6.5826e-01]],\n",
       "\n",
       "           [[6.6397e-01, 6.5692e-01, 7.5365e-01],\n",
       "            [5.7619e-01, 5.9794e-01, 4.8852e-02],\n",
       "            [8.6312e-01, 7.4614e-01, 5.0506e-01]],\n",
       "\n",
       "           [[6.4255e-01, 9.5139e-01, 6.9595e-02],\n",
       "            [2.7627e-01, 7.1097e-01, 8.6536e-02],\n",
       "            [5.0795e-01, 1.4297e-01, 2.6551e-01]]],\n",
       "\n",
       "\n",
       "          [[[4.3535e-01, 3.9875e-01, 3.6979e-01],\n",
       "            [6.1578e-01, 7.2271e-01, 6.2057e-01],\n",
       "            [6.8535e-01, 8.8989e-02, 7.2775e-01]],\n",
       "\n",
       "           [[8.8016e-01, 7.7019e-01, 5.5197e-01],\n",
       "            [4.5309e-01, 9.8273e-01, 6.1166e-01],\n",
       "            [2.1308e-01, 3.6912e-01, 2.6765e-01]],\n",
       "\n",
       "           [[2.2321e-01, 7.4916e-01, 5.9507e-01],\n",
       "            [6.2595e-01, 1.9582e-01, 3.2656e-01],\n",
       "            [8.8116e-02, 4.5938e-01, 7.4719e-01]]],\n",
       "\n",
       "\n",
       "          [[[1.2876e-01, 7.4724e-01, 8.0837e-01],\n",
       "            [4.3804e-01, 8.6039e-02, 9.7784e-01],\n",
       "            [3.6139e-01, 2.5823e-01, 3.4710e-01]],\n",
       "\n",
       "           [[6.3040e-01, 3.5730e-01, 4.5574e-01],\n",
       "            [6.3326e-01, 2.9339e-01, 7.3674e-01],\n",
       "            [4.1477e-01, 5.0102e-01, 2.8251e-01]],\n",
       "\n",
       "           [[6.3591e-01, 1.1618e-01, 2.4397e-01],\n",
       "            [7.3002e-01, 1.1916e-01, 9.3365e-01],\n",
       "            [5.5323e-01, 9.7963e-01, 4.4173e-01]]]]],\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "        [[[[[7.9094e-01, 5.9385e-01, 2.5356e-01],\n",
       "            [1.2521e-01, 9.8411e-01, 7.9847e-01],\n",
       "            [9.3950e-01, 4.5271e-01, 7.7015e-01]],\n",
       "\n",
       "           [[3.4336e-01, 9.3516e-01, 9.5302e-01],\n",
       "            [8.2773e-01, 8.2782e-01, 9.1261e-01],\n",
       "            [7.2249e-01, 1.0324e-01, 5.7378e-01]],\n",
       "\n",
       "           [[8.5542e-02, 8.5971e-01, 3.0225e-01],\n",
       "            [7.1914e-01, 7.1404e-01, 8.7447e-01],\n",
       "            [3.7342e-01, 3.5518e-01, 2.4355e-01]]],\n",
       "\n",
       "\n",
       "          [[[1.7056e-01, 6.9799e-01, 8.7118e-01],\n",
       "            [7.5566e-01, 6.5385e-01, 5.7708e-01],\n",
       "            [3.7372e-01, 6.1144e-01, 8.4047e-01]],\n",
       "\n",
       "           [[8.2690e-01, 3.1495e-01, 5.7256e-01],\n",
       "            [6.0470e-01, 6.7899e-01, 2.3114e-01],\n",
       "            [5.4336e-01, 9.4807e-01, 6.4980e-02]],\n",
       "\n",
       "           [[4.2273e-01, 1.2451e-01, 9.1672e-01],\n",
       "            [8.0319e-01, 7.0693e-01, 2.1957e-01],\n",
       "            [5.8287e-01, 9.2355e-01, 8.9172e-01]]],\n",
       "\n",
       "\n",
       "          [[[4.9123e-01, 5.1478e-01, 8.4902e-01],\n",
       "            [2.1396e-03, 4.8102e-01, 7.5842e-01],\n",
       "            [2.0299e-01, 7.8849e-01, 7.3489e-01]],\n",
       "\n",
       "           [[9.7700e-01, 9.7304e-01, 3.9125e-01],\n",
       "            [4.5057e-01, 3.4194e-01, 7.9399e-01],\n",
       "            [9.6519e-01, 9.1586e-01, 2.5057e-01]],\n",
       "\n",
       "           [[7.5946e-01, 6.4614e-01, 7.6134e-01],\n",
       "            [3.1499e-01, 4.3789e-01, 6.2871e-02],\n",
       "            [5.0890e-02, 5.9630e-01, 4.3595e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[9.0138e-01, 1.6533e-01, 1.0948e-01],\n",
       "            [1.8460e-01, 8.9749e-01, 7.3944e-01],\n",
       "            [6.7261e-01, 7.5488e-01, 6.5149e-02]],\n",
       "\n",
       "           [[8.3599e-01, 5.8165e-01, 8.3949e-01],\n",
       "            [6.0145e-01, 3.4164e-01, 5.7504e-01],\n",
       "            [9.4555e-01, 8.0334e-01, 8.9732e-02]],\n",
       "\n",
       "           [[7.9174e-01, 8.1456e-01, 3.5346e-01],\n",
       "            [7.4253e-01, 8.4262e-02, 4.7875e-01],\n",
       "            [1.8203e-01, 8.1575e-01, 4.2626e-01]]],\n",
       "\n",
       "\n",
       "          [[[9.4817e-01, 2.4802e-02, 4.3124e-01],\n",
       "            [4.1271e-01, 7.6894e-01, 1.2535e-01],\n",
       "            [2.6430e-01, 3.4948e-01, 8.8728e-01]],\n",
       "\n",
       "           [[7.8392e-01, 1.5106e-02, 2.3183e-01],\n",
       "            [1.8588e-01, 2.3909e-01, 3.8213e-01],\n",
       "            [2.4169e-01, 9.9495e-01, 3.6229e-01]],\n",
       "\n",
       "           [[1.1052e-01, 9.4238e-01, 9.0461e-01],\n",
       "            [3.6251e-01, 3.4939e-01, 6.6127e-01],\n",
       "            [8.6501e-01, 6.5311e-01, 3.2930e-01]]],\n",
       "\n",
       "\n",
       "          [[[3.9504e-01, 3.5154e-01, 9.5998e-01],\n",
       "            [2.0092e-02, 6.6833e-01, 1.5624e-01],\n",
       "            [9.2537e-01, 8.7177e-01, 1.2744e-01]],\n",
       "\n",
       "           [[7.2305e-01, 2.9256e-01, 1.9880e-01],\n",
       "            [2.4597e-01, 8.4218e-01, 4.9784e-02],\n",
       "            [5.9919e-01, 4.2288e-01, 3.7657e-01]],\n",
       "\n",
       "           [[4.9741e-01, 4.2732e-01, 2.9618e-01],\n",
       "            [5.4368e-01, 5.5515e-01, 1.1016e-01],\n",
       "            [8.2659e-01, 9.5570e-01, 8.8009e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[6.3133e-01, 5.7600e-01, 8.2587e-01],\n",
       "            [1.4275e-01, 6.8721e-01, 3.1342e-01],\n",
       "            [6.2368e-01, 1.1914e-01, 6.9826e-01]],\n",
       "\n",
       "           [[7.4073e-01, 7.4078e-01, 2.7136e-01],\n",
       "            [3.0682e-01, 6.8662e-01, 6.8706e-01],\n",
       "            [2.1664e-01, 6.7829e-01, 5.5649e-01]],\n",
       "\n",
       "           [[1.1006e-01, 3.0678e-01, 9.3655e-02],\n",
       "            [8.1202e-01, 4.7173e-01, 1.9275e-01],\n",
       "            [1.1817e-01, 9.1096e-01, 6.3464e-01]]],\n",
       "\n",
       "\n",
       "          [[[4.5852e-01, 8.2624e-01, 4.2479e-01],\n",
       "            [9.9991e-01, 6.9491e-01, 7.4435e-01],\n",
       "            [4.0091e-01, 3.0207e-01, 1.1837e-01]],\n",
       "\n",
       "           [[4.7160e-01, 6.1905e-01, 1.9044e-01],\n",
       "            [4.8429e-01, 8.4435e-01, 9.7062e-01],\n",
       "            [4.3417e-01, 9.1387e-02, 5.5924e-01]],\n",
       "\n",
       "           [[5.0591e-01, 1.5908e-01, 5.3447e-01],\n",
       "            [7.7493e-01, 1.2982e-01, 1.4260e-01],\n",
       "            [1.4999e-02, 2.4229e-01, 9.3871e-01]]],\n",
       "\n",
       "\n",
       "          [[[2.0427e-01, 1.7866e-01, 5.3018e-01],\n",
       "            [3.7506e-01, 1.3559e-01, 7.4655e-01],\n",
       "            [9.0141e-01, 1.2356e-01, 9.4190e-01]],\n",
       "\n",
       "           [[8.0688e-01, 5.8379e-02, 8.8637e-01],\n",
       "            [8.6886e-01, 5.5427e-01, 2.5103e-01],\n",
       "            [7.7801e-01, 4.8888e-01, 5.1411e-01]],\n",
       "\n",
       "           [[7.9335e-01, 9.1479e-01, 5.3780e-01],\n",
       "            [9.1381e-01, 6.9702e-01, 6.0006e-01],\n",
       "            [7.4826e-01, 6.1076e-01, 6.7478e-01]]]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(size=(3, 3, 3, 3, 3, 3))\n",
    "\n",
    "random_tensor.dtype\n",
    "random_tensor.shape\n",
    "random_tensor.ndim\n",
    "\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb5eadb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32,\n",
       " torch.Size([3, 3, 3, 3]),\n",
       " 4,\n",
       " tensor([[[[0.2694, 0.2003, 0.8308],\n",
       "           [0.5307, 0.0222, 0.7595],\n",
       "           [0.8940, 0.2017, 0.2350]],\n",
       " \n",
       "          [[0.8042, 0.4462, 0.6251],\n",
       "           [0.0080, 0.6218, 0.1381],\n",
       "           [0.7781, 0.1313, 0.2529]],\n",
       " \n",
       "          [[0.9586, 0.2025, 0.0901],\n",
       "           [0.8432, 0.3056, 0.8726],\n",
       "           [0.8632, 0.5738, 0.3926]]],\n",
       " \n",
       " \n",
       "         [[[0.3222, 0.9165, 0.6165],\n",
       "           [0.5712, 0.9368, 0.6675],\n",
       "           [0.0282, 0.5293, 0.1024]],\n",
       " \n",
       "          [[0.4321, 0.6237, 0.7726],\n",
       "           [0.0188, 0.5168, 0.9985],\n",
       "           [0.4029, 0.9620, 0.8171]],\n",
       " \n",
       "          [[0.9877, 0.2111, 0.1057],\n",
       "           [0.4778, 0.0346, 0.7009],\n",
       "           [0.7755, 0.0059, 0.2881]]],\n",
       " \n",
       " \n",
       "         [[[0.2673, 0.1360, 0.8265],\n",
       "           [0.7468, 0.5877, 0.3397],\n",
       "           [0.0614, 0.9982, 0.9902]],\n",
       " \n",
       "          [[0.8504, 0.1487, 0.9236],\n",
       "           [0.6379, 0.6017, 0.4801],\n",
       "           [0.3908, 0.0694, 0.7813]],\n",
       " \n",
       "          [[0.7607, 0.3227, 0.9782],\n",
       "           [0.7322, 0.0535, 0.4278],\n",
       "           [0.5920, 0.1465, 0.8121]]]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of 4dim:\n",
    "random_tensor_4d = torch.rand(size=(3, 3, 3, 3))\n",
    "random_tensor_4d.dtype, random_tensor.shape, random_tensor.ndim, random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fccf65e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (224, 224, 3)\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "random_image_size_tensor.shape\n",
    "random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2636180c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In torch, '.size()' essentially does the same thing as '.shape' ; \n",
    "random_image_size_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cde47fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros.dtype\n",
    "zeros.size()\n",
    "zeros.ndim\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11ea9964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 3, 3))\n",
    "ones.dtype\n",
    "ones.size()\n",
    "ones.ndim\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb257db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating a range and tensors like\n",
    "Sometimes you might want a range of numbers, such as 1 to 10 or 0 to 100.\n",
    "\n",
    "You can use torch.arange(start, end, step) to do so.\n",
    "\n",
    "Where:\n",
    "\n",
    "start = start of range (e.g. 0)\n",
    "end = end of range (e.g. 10)\n",
    "step = how many steps in between each value (e.g. 1)\n",
    "Note: In Python, you can use range() to create a range. However in PyTorch, torch.range() is deprecated and may show an error in the future.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45edc8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange(), torch.range() is deprecated \n",
    "zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n",
    "\n",
    "# Create a range of values 0 to 10\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten.shape\n",
    "zero_to_ten.ndim\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d954ac09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also create a tensor of zeros similar to another tensor\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten) # will have same shape\n",
    "ten_zeros.shape\n",
    "ten_zeros.ndim\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dccf61",
   "metadata": {},
   "source": [
    "### Tensor datatypes\n",
    "\n",
    "There are many different [tensor datatypes available in PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "\n",
    "Some are specific for CPU and some are better for GPU.\n",
    "\n",
    "Getting to know which one can take some time.\n",
    "\n",
    "Generally if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).\n",
    "\n",
    "The most common type (and generally the default) is `torch.float32` or `torch.float`.\n",
    "\n",
    "This is referred to as \"32-bit floating point\".\n",
    "\n",
    "But there's also 16-bit floating point (`torch.float16` or `torch.half`) and 64-bit floating point (`torch.float64` or `torch.double`).\n",
    "\n",
    "And to confuse things even more there's also 8-bit, 16-bit, 32-bit and 64-bit integers.\n",
    "\n",
    "Plus more!\n",
    "\n",
    "> **Note:** An integer is a flat round number like `7` whereas a float has a decimal `7.0`.\n",
    "\n",
    "The reason for all of these is to do with **precision in computing**.\n",
    "\n",
    "Precision is the amount of detail used to describe a number.\n",
    "\n",
    "The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
    "\n",
    "This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use.\n",
    "\n",
    "So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate).\n",
    "\n",
    "> **Resources:** \n",
    "  * See the [PyTorch documentation for a list of all available tensor datatypes](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "  * Read the [Wikipedia page for an overview of what precision in computing](https://en.wikipedia.org/wiki/Precision_(computer_science)) is.\n",
    "\n",
    "Let's see how to create some tensors with specific datatypes. We can do so using the `dtype` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "280cb271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or w/e dtype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a84f57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float16) # torch.half would also work\n",
    "\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d06a6dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchHalf_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.half) # torch.half would also work\n",
    "\n",
    "torchHalf_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa115182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_64_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float64) # torch.double would also work (for float64)\n",
    "\n",
    "float_64_tensor.dtype\n",
    "\n",
    "double_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.double)\n",
    "double_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a674f7f",
   "metadata": {},
   "source": [
    "## Getting information from tensors\n",
    "\n",
    "Once you've created tensors (or someone else or a PyTorch module has created them for you), you might want to get some information from them.\n",
    "\n",
    "We've seen these before but three of the most common attributes you'll want to find out about tensors are:\n",
    "* `shape` - what shape is the tensor? (some operations require specific shape rules)\n",
    "* `dtype` - what datatype are the elements within the tensor stored in?\n",
    "* `device` - what device is the tensor stored on? (usually GPU or CPU)\n",
    "\n",
    "Let's create a random tensor and find out details about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9c0757e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 348 µs, sys: 150 µs, total: 498 µs\n",
      "Wall time: 426 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909be3d9",
   "metadata": {},
   "source": [
    "One of the most common errors in deep learning (shape errors)\n",
    "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most common errors you'll run into in deep learning is shape mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a05206e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "tensor_A.shape\n",
    "tensor_A.ndim\n",
    "\n",
    "tensor_B.shape\n",
    "tensor_B.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29545a4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmatmul(tensor_A, tensor_B)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "torch.matmul(tensor_A, tensor_B) # (this will error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94545456",
   "metadata": {},
   "source": [
    "We can make matrix multiplication work between `tensor_A` and `tensor_B` by making their inner dimensions match.\n",
    "\n",
    "One of the ways to do this is with a **transpose** (switch the dimensions of a given tensor).\n",
    "\n",
    "You can perform transposes in PyTorch using either:\n",
    "* `torch.transpose(input, dim0, dim1)` - where `input` is the desired tensor to transpose and `dim0` and `dim1` are the dimensions to be swapped.\n",
    "* `tensor.T` - where `tensor` is the desired tensor to transpose.\n",
    "\n",
    "Let's try the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b902fcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7., 10.],\n",
      "        [ 8., 11.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B\n",
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "760c6b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B.T\n",
    "print(tensor_A)\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9516e158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape\n",
    "tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af31dd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mm is a shortcut for matmul\n",
    "torch.mm(tensor_A, tensor_B.T)\n",
    "\n",
    "torch.mm(tensor_A, tensor_B.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4036ff87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4120, 1.1040, 0.7523, 0.6512, 0.6170, 0.9885, 0.3243, 0.7400],\n",
       "        [0.5031, 1.1139, 0.5873, 0.8720, 0.5758, 0.9372, 0.3013, 0.9043],\n",
       "        [0.5997, 1.2261, 0.9423, 1.1992, 0.7898, 1.1674, 0.6103, 1.0811],\n",
       "        [0.3340, 1.1927, 0.8644, 0.3756, 0.6480, 1.0722, 0.2570, 0.5978]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(torch.rand(4,3),torch.rand(3,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745a1df",
   "metadata": {},
   "source": [
    "### MATRIX MULTIPLICATION RULES: ###\n",
    "\n",
    "*There are two (2) main rules that performing matrix multiplication (matmul; mm;) must satisfy:\n",
    "\n",
    "1. The **inner dimensions** must match:\n",
    "*e.g.,*\n",
    "\n",
    "    **(2, 3) @ (2, 3) :** `torch.mm(torch.rand(2, 3), torch.rand(2, 3))` will *NOT* work\n",
    "    \n",
    "    **(3, 2) @ (2, 3) :** `torch.mm(torch.rand(3, 2), torch.rand(2, 3))` *WILL* work\n",
    "    \n",
    "    **(2, 3) @ (3, 2) :**`torch.mm(torch.rand(2, 3), torch.rand(3, 2))` *WILL* work\n",
    "    \n",
    "    **(2, 3) @ (2, 3).T :** `torch.mm(torch.rand(2, 3), torch.rand(2, 3).T)` *WILL* work\n",
    "    \n",
    "    \n",
    "2. The resulting matrix takes the shape of the **outer dimensions**:\n",
    "\n",
    "    A torch.mm of `(2, 3) @ (3, 2)` becomes --> `(2, 2)` matrix;\n",
    "    \n",
    "    A torch.mm of `(2, 3) @ (3, 2)` becomes --> `(3, 3)` matrix;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca57a151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2265, 0.6733],\n",
       "        [0.6175, 1.0073]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5175, 0.5101],\n",
       "        [1.1503, 1.2939]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(torch.rand(2, 3), torch.rand(2, 3).T)\n",
    "torch.mm(torch.rand(2, 3), torch.rand(3, 2))\n",
    "# torch.mm(torch.rand(8, 2).T, torch.rand(2, 8).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "488914fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2420, 0.0979, 0.2403, 0.2608, 0.1241, 0.2774, 0.2419, 0.2920],\n",
       "        [0.2792, 0.2905, 0.3508, 0.4608, 0.3994, 0.3542, 0.3243, 0.4859],\n",
       "        [0.1687, 0.3895, 0.3006, 0.4712, 0.5500, 0.2552, 0.2506, 0.4731],\n",
       "        [1.0355, 0.7763, 1.1762, 1.4378, 1.0465, 1.2557, 1.1261, 1.5493],\n",
       "        [0.5930, 0.5692, 0.7252, 0.9357, 0.7791, 0.7431, 0.6767, 0.9918],\n",
       "        [0.6842, 0.3937, 0.7277, 0.8426, 0.5194, 0.8067, 0.7136, 0.9237],\n",
       "        [0.6143, 0.3151, 0.6375, 0.7220, 0.4110, 0.7169, 0.6309, 0.7971],\n",
       "        [0.5571, 0.3402, 0.6007, 0.7038, 0.4512, 0.6607, 0.5861, 0.7686]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2.7340, 1.9753],\n",
       "        [2.4835, 1.9235]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(torch.rand(8, 2), torch.rand(2, 8))\n",
    "\n",
    "torch.mm(torch.rand(8, 2).T, torch.rand(2, 8).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "661aa47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0628, 1.4853, 2.0440],\n",
       "        [2.0335, 1.0406, 1.5072],\n",
       "        [3.4601, 1.8795, 2.3197]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.1957, 0.8967, 1.0496, 0.7040, 0.8018, 0.7409, 1.4560, 0.7708, 1.7074],\n",
       "        [0.7084, 0.4866, 0.8765, 0.4712, 0.5757, 0.5750, 0.9336, 0.4766, 1.1346],\n",
       "        [0.4748, 0.1760, 0.3246, 0.3059, 0.2052, 0.1718, 0.5126, 0.1336, 0.5602],\n",
       "        [0.9052, 0.3327, 1.0310, 0.6544, 0.5813, 0.5736, 1.1062, 0.3455, 1.2930],\n",
       "        [1.3272, 0.8070, 1.1949, 0.8306, 0.8301, 0.7701, 1.5872, 0.7037, 1.8412],\n",
       "        [1.1577, 1.0945, 0.9231, 0.6127, 0.8216, 0.7459, 1.4264, 0.9158, 1.6866],\n",
       "        [1.5595, 1.2828, 1.1681, 0.8572, 0.9968, 0.8881, 1.8588, 1.0553, 2.1590],\n",
       "        [1.3556, 0.8830, 0.8900, 0.7779, 0.7175, 0.6103, 1.5291, 0.6935, 1.7212],\n",
       "        [1.3405, 1.0219, 1.1683, 0.7838, 0.9015, 0.8318, 1.6330, 0.8762, 1.9157]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.3540, 0.5239, 0.7215, 1.4408, 0.8513, 0.9422, 1.1037, 0.4503, 1.1978],\n",
       "        [1.3284, 0.5861, 0.6649, 1.4211, 0.7920, 0.8610, 1.2192, 0.5016, 1.0995],\n",
       "        [0.6404, 0.5275, 0.2045, 0.7203, 0.2589, 0.2284, 1.0142, 0.4254, 0.3137],\n",
       "        [0.3552, 0.3381, 0.2473, 0.4571, 0.2429, 0.2390, 0.4540, 0.1701, 0.3427],\n",
       "        [1.1849, 0.5751, 0.6012, 1.2859, 0.7061, 0.7592, 1.1388, 0.4654, 0.9788],\n",
       "        [0.6614, 0.6514, 0.4698, 0.8606, 0.4568, 0.4470, 0.8595, 0.3204, 0.6452],\n",
       "        [0.6926, 0.5997, 0.2815, 0.8076, 0.3237, 0.2949, 1.0581, 0.4342, 0.4132],\n",
       "        [1.8345, 1.0250, 0.9266, 2.0298, 1.0725, 1.1293, 1.9254, 0.7831, 1.4765],\n",
       "        [1.1463, 0.6531, 0.5296, 1.2560, 0.6297, 0.6549, 1.2776, 0.5268, 0.8531]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(torch.rand(3, 9), torch.rand(9, 3))\n",
    "\n",
    "torch.mm(torch.rand(3, 9).T, torch.rand(9, 3).T)\n",
    "torch.mm(torch.rand(9, 3), torch.rand(3, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ec331e43",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x4 and 3x4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# If the inner dimensions DON'T match (e.g. `(3, 4) @ (3, 4)`), you will get a 'shape error':\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m torch\u001b[38;5;241m.\u001b[39mmm(torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m), torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x4 and 3x4)"
     ]
    }
   ],
   "source": [
    "# If the inner dimensions DON'T match (e.g. `(3, 4) @ (3, 4)`), you will get a 'shape error':\n",
    "\n",
    "torch.mm(torch.rand(3, 4), torch.rand(3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96802db0",
   "metadata": {},
   "source": [
    "### NOTE: SHAPE ERRORS (^^^) ARE ONE OF THE MOST COMMON ERRORS IN DL / NN!!! ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "805ddede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.,  8.,  9.],\n",
       "        [10., 11., 12.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape\n",
    "tensor_A\n",
    "\n",
    "tensor_B.T.shape\n",
    "tensor_B.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24520f2e",
   "metadata": {},
   "source": [
    "### torch.nn.Linear() ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94972381",
   "metadata": {},
   "source": [
    "Neural networks are full of matrix multiplications and dot products.\n",
    "\n",
    "The [`torch.nn.Linear()`](https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html) module (we'll see this in action later on), also known as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input `x` and a weights matrix `A`.\n",
    "\n",
    "$$\n",
    "y = x\\cdot{A^T} + b\n",
    "$$\n",
    "\n",
    "Where:\n",
    "* `x` is the input to the layer (deep learning is a stack of layers like `torch.nn.Linear()` and others on top of each other).\n",
    "* `A` is the weights matrix created by the layer, this starts out as random numbers that get adjusted as a neural network learns to better represent patterns in the data (notice the \"`T`\", that's because the weights matrix gets transposed).\n",
    "  * **Note:** You might also often see `W` or another letter like `X` used to showcase the weights matrix.\n",
    "* `b` is the bias term used to slightly offset the weights and inputs.\n",
    "* `y` is the output (a manipulation of the input in the hopes to discover patterns in it).\n",
    "\n",
    "This is a linear function (you may have seen something like $y = mx+b$ in high school or elsewhere), and can be used to draw a straight line!\n",
    "\n",
    "Let's play around with a linear layer.\n",
    "\n",
    "Try changing the values of `in_features` and `out_features` below and see what happens.\n",
    "\n",
    "Do you notice anything to do with the shapes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be256752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x132ba5830>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(42)\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input \n",
    "                         out_features=6) # out_features = describes outer value \n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d00e5fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x132ba5830>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[-0.2647, -0.1677,  0.7681, -0.4541, -0.7028, -0.6111],\n",
      "        [-0.0671, -0.8661,  0.9346, -1.4063, -2.4837, -0.5289],\n",
      "        [ 0.1305, -1.5645,  1.1011, -2.3585, -4.2646, -0.4468]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(27)\n",
    "\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2 # in_features = matches inner dimension of input \n",
    "                         , out_features=6) # out_features = describes outer value \n",
    "\n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e124a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03437ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b49576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d375d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0b25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c324d877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b22ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
