{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "02b7d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f8941b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3487836f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5b31ed01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7, 7])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.tensor([7, 7, 7])\n",
    "t1\n",
    "t1.shape\n",
    "t1.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "49aa656a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "matrix = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "matrix\n",
    "\n",
    "matrix.shape\n",
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0e266ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12],\n",
       "        [13, 14]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "matrix = torch.tensor([[7, 8], \n",
    "                       [9, 10],\n",
    "                       [11, 12],\n",
    "                       [13, 14]]\n",
    "                     )\n",
    "matrix\n",
    "\n",
    "matrix.shape\n",
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4b14a6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "TENSOR\n",
    "TENSOR.shape\n",
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5ade8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "277e292a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "31d4fe6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "tensor3d\n",
    "tensor3d.shape\n",
    "tensor3d.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "91dc8250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[[[7.6469e-01, 7.8510e-01, 2.1175e-02],\n",
       "            [2.2299e-01, 6.5125e-01, 3.9547e-01],\n",
       "            [8.1113e-01, 2.5580e-01, 7.5705e-01]],\n",
       "\n",
       "           [[3.9516e-01, 8.0950e-01, 3.7291e-01],\n",
       "            [3.4508e-01, 2.5110e-01, 4.7198e-01],\n",
       "            [6.6841e-01, 1.9053e-01, 1.4895e-01]],\n",
       "\n",
       "           [[6.7143e-01, 4.7191e-01, 5.0533e-01],\n",
       "            [4.9091e-01, 7.7929e-01, 3.2457e-01],\n",
       "            [1.2489e-01, 1.3912e-01, 5.2219e-01]]],\n",
       "\n",
       "\n",
       "          [[[8.1909e-01, 7.0398e-01, 3.2640e-01],\n",
       "            [8.4172e-02, 5.9629e-01, 4.7422e-01],\n",
       "            [9.0014e-01, 3.3085e-01, 7.6095e-01]],\n",
       "\n",
       "           [[3.2282e-01, 9.6095e-02, 3.0749e-01],\n",
       "            [9.4713e-02, 4.7450e-01, 8.7923e-01],\n",
       "            [4.8798e-01, 7.1430e-01, 7.4669e-01]],\n",
       "\n",
       "           [[2.2591e-01, 4.5535e-01, 5.5081e-01],\n",
       "            [7.9656e-01, 4.5940e-01, 4.0065e-01],\n",
       "            [1.3463e-02, 6.3334e-03, 3.6442e-01]]],\n",
       "\n",
       "\n",
       "          [[[1.8060e-01, 6.2468e-01, 1.9719e-01],\n",
       "            [4.2716e-01, 4.6546e-01, 4.6799e-01],\n",
       "            [7.4093e-02, 9.9095e-01, 4.1521e-01]],\n",
       "\n",
       "           [[2.4186e-01, 3.3051e-01, 5.0169e-01],\n",
       "            [6.6001e-01, 3.1098e-01, 4.8915e-01],\n",
       "            [1.2751e-01, 2.5411e-01, 2.5838e-01]],\n",
       "\n",
       "           [[1.8570e-01, 4.3549e-01, 3.7408e-01],\n",
       "            [4.6409e-01, 7.3689e-02, 4.6153e-01],\n",
       "            [6.5764e-01, 7.5791e-01, 3.6766e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[5.7776e-02, 7.6714e-01, 6.5535e-01],\n",
       "            [1.0908e-01, 2.0696e-01, 1.9488e-01],\n",
       "            [9.2644e-01, 6.0564e-01, 5.7794e-01]],\n",
       "\n",
       "           [[5.1566e-01, 1.5343e-01, 2.4292e-01],\n",
       "            [1.3227e-01, 6.3077e-01, 9.2522e-01],\n",
       "            [6.5450e-01, 4.4594e-01, 8.7799e-01]],\n",
       "\n",
       "           [[9.0907e-01, 8.6188e-01, 1.8711e-01],\n",
       "            [3.4274e-01, 1.5672e-01, 1.1839e-01],\n",
       "            [3.9177e-01, 2.0863e-01, 9.5200e-01]]],\n",
       "\n",
       "\n",
       "          [[[1.4443e-01, 6.1865e-01, 1.0261e-02],\n",
       "            [2.7296e-01, 2.1636e-01, 1.1539e-01],\n",
       "            [9.7054e-02, 6.3121e-02, 8.7211e-01]],\n",
       "\n",
       "           [[5.7183e-01, 7.5246e-01, 4.3173e-01],\n",
       "            [7.5480e-01, 5.0660e-01, 5.5368e-01],\n",
       "            [4.8309e-01, 7.9298e-01, 2.8646e-01]],\n",
       "\n",
       "           [[3.1868e-01, 3.7943e-02, 6.0297e-01],\n",
       "            [5.3082e-01, 6.2306e-01, 7.0301e-01],\n",
       "            [7.1032e-01, 3.8336e-01, 8.6251e-01]]],\n",
       "\n",
       "\n",
       "          [[[9.0577e-01, 6.6277e-01, 1.7036e-01],\n",
       "            [8.4386e-01, 7.4619e-01, 6.3658e-01],\n",
       "            [8.9666e-01, 2.5410e-01, 9.8364e-01]],\n",
       "\n",
       "           [[5.9973e-02, 9.6653e-01, 6.9168e-01],\n",
       "            [4.5575e-01, 5.0543e-01, 8.5902e-01],\n",
       "            [6.6912e-01, 8.9429e-01, 3.0196e-01]],\n",
       "\n",
       "           [[7.7395e-01, 8.4369e-01, 3.4553e-01],\n",
       "            [8.9645e-01, 8.5227e-01, 6.4975e-01],\n",
       "            [7.1101e-01, 6.7872e-01, 6.8665e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[6.1501e-01, 7.9866e-01, 5.8603e-01],\n",
       "            [3.1250e-01, 6.6774e-02, 6.4414e-02],\n",
       "            [5.9809e-01, 4.4198e-01, 2.8921e-01]],\n",
       "\n",
       "           [[3.0132e-01, 8.9722e-01, 4.2320e-01],\n",
       "            [5.7297e-01, 6.1854e-01, 7.4749e-01],\n",
       "            [2.9663e-01, 6.7014e-01, 1.9422e-01]],\n",
       "\n",
       "           [[2.8944e-01, 4.0787e-01, 3.4344e-01],\n",
       "            [8.5830e-01, 3.1812e-01, 7.2675e-01],\n",
       "            [4.4552e-01, 9.4119e-01, 1.5616e-01]]],\n",
       "\n",
       "\n",
       "          [[[4.8170e-01, 3.5404e-01, 9.0890e-01],\n",
       "            [4.9653e-01, 9.1612e-01, 6.4854e-01],\n",
       "            [4.1471e-01, 4.2006e-01, 2.3938e-01]],\n",
       "\n",
       "           [[3.1680e-01, 4.0070e-01, 9.1803e-01],\n",
       "            [8.6836e-01, 9.6201e-02, 4.2717e-01],\n",
       "            [7.9263e-01, 7.2921e-01, 3.4441e-01]],\n",
       "\n",
       "           [[2.5307e-01, 1.6471e-01, 6.9794e-02],\n",
       "            [3.9332e-03, 4.6343e-01, 9.4011e-01],\n",
       "            [4.0762e-01, 4.5642e-01, 4.9627e-01]]],\n",
       "\n",
       "\n",
       "          [[[7.8914e-01, 9.2288e-01, 4.3138e-01],\n",
       "            [2.0934e-01, 2.9438e-01, 4.5490e-02],\n",
       "            [4.3488e-01, 4.3680e-01, 8.4559e-03]],\n",
       "\n",
       "           [[1.5527e-01, 2.9508e-01, 5.6314e-01],\n",
       "            [7.1624e-01, 1.3285e-01, 8.3911e-02],\n",
       "            [9.0305e-01, 9.1417e-01, 9.6266e-01]],\n",
       "\n",
       "           [[5.9325e-01, 4.5065e-01, 3.9114e-01],\n",
       "            [3.1269e-01, 1.8316e-01, 4.8053e-01],\n",
       "            [5.7116e-01, 2.4002e-01, 3.7383e-01]]]]],\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "        [[[[[3.5549e-01, 4.7860e-01, 6.6143e-01],\n",
       "            [9.8799e-01, 7.9623e-01, 4.4050e-01],\n",
       "            [2.6762e-01, 7.0346e-01, 8.9976e-01]],\n",
       "\n",
       "           [[6.6967e-01, 9.6072e-01, 6.2595e-01],\n",
       "            [4.2014e-02, 3.3162e-01, 7.3692e-01],\n",
       "            [2.3334e-01, 5.1205e-01, 6.1710e-01]],\n",
       "\n",
       "           [[4.5250e-01, 3.5834e-01, 6.4124e-01],\n",
       "            [9.5936e-01, 2.1954e-01, 2.9407e-01],\n",
       "            [8.3323e-01, 5.8273e-01, 1.9347e-01]]],\n",
       "\n",
       "\n",
       "          [[[3.8546e-01, 4.3793e-01, 9.6485e-01],\n",
       "            [4.9575e-02, 9.6559e-01, 1.2795e-01],\n",
       "            [1.6514e-01, 5.7175e-01, 3.1123e-01]],\n",
       "\n",
       "           [[1.1479e-01, 4.8788e-01, 2.8221e-01],\n",
       "            [2.5447e-01, 3.6439e-01, 1.4578e-01],\n",
       "            [9.4500e-01, 3.4676e-01, 4.7791e-01]],\n",
       "\n",
       "           [[8.4921e-01, 2.3918e-01, 4.6479e-01],\n",
       "            [7.1494e-01, 9.3927e-01, 7.8431e-01],\n",
       "            [3.1147e-01, 4.7585e-01, 5.3466e-01]]],\n",
       "\n",
       "\n",
       "          [[[1.8372e-02, 8.6265e-02, 5.0396e-01],\n",
       "            [2.3206e-01, 6.8445e-01, 9.2153e-01],\n",
       "            [2.8552e-01, 6.6762e-01, 6.2807e-01]],\n",
       "\n",
       "           [[5.0435e-02, 8.4251e-01, 2.5738e-01],\n",
       "            [4.4578e-01, 8.5444e-02, 8.3715e-01],\n",
       "            [1.0382e-01, 8.5333e-01, 5.5390e-01]],\n",
       "\n",
       "           [[2.8605e-01, 3.7763e-01, 5.8412e-02],\n",
       "            [3.9470e-04, 9.4000e-01, 3.6262e-01],\n",
       "            [1.5825e-01, 4.5926e-01, 1.2596e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[6.7344e-01, 4.3848e-01, 2.9604e-01],\n",
       "            [6.8468e-01, 8.1672e-01, 3.3352e-01],\n",
       "            [1.3383e-01, 2.3536e-01, 2.3145e-01]],\n",
       "\n",
       "           [[3.3419e-01, 4.6630e-01, 1.0931e-01],\n",
       "            [8.5633e-01, 8.0807e-01, 7.1036e-01],\n",
       "            [1.7939e-01, 3.3625e-01, 2.8874e-01]],\n",
       "\n",
       "           [[1.3234e-02, 2.9954e-01, 1.3125e-01],\n",
       "            [3.0441e-01, 5.7170e-01, 5.6701e-01],\n",
       "            [4.9493e-01, 4.7529e-01, 3.5126e-01]]],\n",
       "\n",
       "\n",
       "          [[[7.9027e-01, 4.6747e-01, 6.3031e-01],\n",
       "            [9.4102e-01, 6.2816e-01, 1.6180e-02],\n",
       "            [5.2364e-01, 5.3432e-01, 4.7376e-01]],\n",
       "\n",
       "           [[5.6945e-01, 3.0564e-01, 3.3078e-01],\n",
       "            [4.6566e-01, 3.7529e-01, 6.4015e-01],\n",
       "            [3.9702e-01, 5.2449e-01, 1.6739e-01]],\n",
       "\n",
       "           [[8.5015e-01, 4.1830e-02, 2.2175e-01],\n",
       "            [4.3318e-01, 3.5614e-01, 2.2714e-01],\n",
       "            [3.3815e-01, 5.5220e-01, 8.2546e-01]]],\n",
       "\n",
       "\n",
       "          [[[2.6687e-01, 4.8456e-01, 7.5649e-01],\n",
       "            [8.1789e-01, 1.4752e-02, 7.1555e-01],\n",
       "            [1.2209e-01, 7.1360e-01, 2.7099e-01]],\n",
       "\n",
       "           [[2.8307e-01, 6.0794e-01, 1.4551e-01],\n",
       "            [4.6915e-02, 7.3319e-01, 1.2200e-01],\n",
       "            [2.2159e-02, 2.6564e-02, 5.9837e-01]],\n",
       "\n",
       "           [[8.5061e-01, 5.3840e-01, 4.0155e-01],\n",
       "            [7.7412e-01, 5.8493e-01, 6.7914e-01],\n",
       "            [3.7547e-01, 9.1157e-01, 3.7139e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[5.4856e-01, 7.0981e-02, 7.9000e-01],\n",
       "            [7.4343e-01, 4.8418e-01, 8.5741e-01],\n",
       "            [2.8981e-01, 3.2981e-01, 7.7104e-01]],\n",
       "\n",
       "           [[4.8463e-01, 4.1645e-02, 6.3086e-01],\n",
       "            [1.7285e-01, 7.6978e-01, 5.2392e-01],\n",
       "            [8.3671e-02, 3.7145e-01, 7.0877e-02]],\n",
       "\n",
       "           [[3.8632e-01, 4.9742e-01, 9.2393e-01],\n",
       "            [3.3123e-01, 1.8142e-01, 4.1571e-01],\n",
       "            [8.8481e-01, 7.3077e-01, 6.5775e-01]]],\n",
       "\n",
       "\n",
       "          [[[2.2159e-01, 6.2436e-01, 4.1516e-01],\n",
       "            [3.6802e-01, 9.1472e-02, 9.8434e-01],\n",
       "            [1.7082e-01, 2.4067e-01, 1.1937e-01]],\n",
       "\n",
       "           [[9.3815e-01, 5.8985e-01, 8.2358e-01],\n",
       "            [7.8324e-01, 9.5046e-02, 4.4834e-01],\n",
       "            [7.6981e-01, 3.8918e-01, 9.4982e-01]],\n",
       "\n",
       "           [[3.4251e-01, 3.1123e-01, 7.7477e-01],\n",
       "            [8.6503e-01, 1.7707e-01, 3.6442e-01],\n",
       "            [6.7267e-01, 8.6901e-01, 3.1579e-01]]],\n",
       "\n",
       "\n",
       "          [[[4.8348e-01, 2.0646e-01, 1.4954e-01],\n",
       "            [9.9505e-01, 1.0459e-01, 6.1245e-01],\n",
       "            [2.0290e-01, 3.5398e-01, 4.7850e-01]],\n",
       "\n",
       "           [[4.6810e-01, 1.8337e-01, 5.8640e-01],\n",
       "            [3.1872e-01, 6.9922e-01, 8.5660e-01],\n",
       "            [8.8662e-01, 9.6187e-02, 1.9122e-01]],\n",
       "\n",
       "           [[1.2202e-01, 7.8297e-01, 7.4003e-01],\n",
       "            [1.0903e-01, 9.4326e-01, 9.4287e-01],\n",
       "            [6.4782e-01, 7.7772e-01, 9.1299e-02]]]]],\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "        [[[[[7.9368e-01, 9.7209e-02, 5.4696e-01],\n",
       "            [3.3596e-01, 3.9064e-01, 9.2346e-01],\n",
       "            [5.5065e-01, 1.6960e-02, 2.5797e-01]],\n",
       "\n",
       "           [[8.4714e-01, 1.3235e-01, 2.8531e-01],\n",
       "            [6.7974e-01, 7.9437e-01, 6.8614e-01],\n",
       "            [8.7209e-01, 9.0995e-01, 7.1983e-01]],\n",
       "\n",
       "           [[2.5925e-01, 5.4048e-01, 7.7654e-01],\n",
       "            [9.5422e-01, 1.4212e-01, 7.1834e-01],\n",
       "            [6.8096e-01, 7.9718e-01, 5.4535e-01]]],\n",
       "\n",
       "\n",
       "          [[[6.2240e-01, 6.1406e-01, 9.1861e-01],\n",
       "            [5.0582e-02, 1.1539e-01, 3.5163e-01],\n",
       "            [9.6591e-01, 7.7915e-01, 4.1581e-01]],\n",
       "\n",
       "           [[1.0531e-01, 2.1874e-01, 8.8520e-01],\n",
       "            [7.4491e-01, 6.0989e-01, 6.7115e-01],\n",
       "            [1.7365e-01, 7.5971e-01, 9.1154e-01]],\n",
       "\n",
       "           [[3.2445e-01, 2.3253e-01, 2.6340e-01],\n",
       "            [3.8964e-01, 8.0203e-01, 7.0265e-01],\n",
       "            [6.5608e-01, 9.5109e-01, 7.1844e-01]]],\n",
       "\n",
       "\n",
       "          [[[3.2590e-01, 8.8256e-01, 1.0972e-01],\n",
       "            [9.0402e-01, 8.3448e-01, 7.5354e-01],\n",
       "            [5.6869e-01, 2.0246e-01, 6.0300e-01]],\n",
       "\n",
       "           [[5.1225e-01, 3.4326e-01, 6.8838e-01],\n",
       "            [2.6944e-01, 2.3839e-01, 2.8687e-01],\n",
       "            [4.9564e-02, 2.5456e-01, 7.2829e-01]],\n",
       "\n",
       "           [[1.0075e-01, 5.0191e-01, 1.0753e-01],\n",
       "            [8.5032e-01, 2.4316e-01, 2.1889e-01],\n",
       "            [5.9764e-01, 5.4849e-01, 3.1869e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[3.6471e-01, 1.9827e-01, 1.7498e-01],\n",
       "            [3.5600e-01, 5.7306e-02, 5.2425e-01],\n",
       "            [7.8497e-01, 9.9008e-01, 2.1721e-01]],\n",
       "\n",
       "           [[5.6987e-01, 9.4744e-01, 6.5185e-01],\n",
       "            [1.7614e-01, 8.9785e-01, 9.2565e-02],\n",
       "            [7.9519e-03, 6.8749e-01, 6.6106e-01]],\n",
       "\n",
       "           [[8.0409e-01, 1.1782e-01, 1.3923e-01],\n",
       "            [4.5983e-01, 9.3526e-01, 2.5100e-01],\n",
       "            [2.0348e-02, 7.1909e-01, 9.7334e-01]]],\n",
       "\n",
       "\n",
       "          [[[9.3790e-01, 8.8944e-01, 5.6981e-01],\n",
       "            [5.6213e-01, 6.3487e-01, 9.8651e-01],\n",
       "            [7.5511e-01, 9.3583e-01, 4.2398e-01]],\n",
       "\n",
       "           [[7.5872e-01, 3.6347e-02, 1.9162e-01],\n",
       "            [2.9752e-01, 4.3878e-01, 8.8009e-01],\n",
       "            [5.2671e-02, 5.8059e-01, 7.2696e-01]],\n",
       "\n",
       "           [[1.6552e-01, 9.5327e-01, 2.3179e-01],\n",
       "            [3.0603e-02, 5.5306e-01, 3.7268e-01],\n",
       "            [7.9984e-01, 7.7092e-01, 5.4593e-02]]],\n",
       "\n",
       "\n",
       "          [[[8.7335e-01, 9.1730e-01, 6.3313e-01],\n",
       "            [5.2856e-01, 2.1470e-01, 9.7362e-01],\n",
       "            [2.1127e-01, 3.6367e-01, 5.2883e-01]],\n",
       "\n",
       "           [[5.6714e-01, 7.5829e-01, 9.5019e-01],\n",
       "            [5.5579e-01, 6.6487e-01, 7.0640e-01],\n",
       "            [9.9428e-01, 2.8061e-02, 6.3905e-02]],\n",
       "\n",
       "           [[7.2363e-01, 5.0427e-01, 3.0272e-01],\n",
       "            [7.4501e-01, 9.6445e-02, 8.9505e-01],\n",
       "            [9.6583e-01, 4.3124e-01, 2.2702e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[4.8218e-01, 9.0669e-01, 2.8309e-01],\n",
       "            [6.7350e-01, 5.3660e-02, 4.7294e-02],\n",
       "            [2.4013e-01, 8.8196e-01, 9.4389e-01]],\n",
       "\n",
       "           [[7.1560e-01, 1.3613e-01, 3.7841e-01],\n",
       "            [4.2939e-01, 1.4343e-01, 2.9755e-01],\n",
       "            [2.1166e-01, 1.8599e-01, 9.4931e-01]],\n",
       "\n",
       "           [[9.8450e-01, 8.4596e-01, 8.5669e-02],\n",
       "            [4.7274e-01, 3.6919e-01, 8.8082e-01],\n",
       "            [7.2386e-01, 9.1689e-01, 4.8784e-01]]],\n",
       "\n",
       "\n",
       "          [[[9.0964e-01, 7.4297e-01, 7.6782e-01],\n",
       "            [9.3109e-01, 8.2148e-02, 6.8741e-01],\n",
       "            [1.1629e-01, 6.8250e-01, 5.8813e-01]],\n",
       "\n",
       "           [[6.1577e-01, 2.7318e-01, 2.3844e-01],\n",
       "            [9.7189e-01, 6.5766e-01, 9.7445e-01],\n",
       "            [5.7526e-01, 7.9203e-01, 6.9937e-01]],\n",
       "\n",
       "           [[3.5996e-01, 9.9860e-01, 1.6773e-01],\n",
       "            [8.5462e-01, 9.2275e-01, 5.7614e-01],\n",
       "            [9.1881e-01, 1.0888e-01, 6.3670e-01]]],\n",
       "\n",
       "\n",
       "          [[[5.1861e-01, 9.3236e-01, 3.6904e-02],\n",
       "            [6.4370e-01, 4.6868e-01, 6.6266e-01],\n",
       "            [5.1057e-01, 1.9011e-01, 1.7798e-01]],\n",
       "\n",
       "           [[5.3566e-01, 2.2686e-01, 6.9717e-01],\n",
       "            [9.7683e-01, 7.5543e-01, 9.1582e-01],\n",
       "            [9.5858e-01, 8.3453e-01, 6.7742e-01]],\n",
       "\n",
       "           [[5.8065e-01, 6.7324e-01, 3.5618e-01],\n",
       "            [1.6840e-01, 1.5441e-01, 2.9741e-01],\n",
       "            [6.9324e-02, 7.0007e-01, 2.8135e-01]]]]]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(size=(3, 3, 3, 3, 3, 3))\n",
    "\n",
    "random_tensor.dtype\n",
    "random_tensor.shape\n",
    "random_tensor.ndim\n",
    "\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a44f8935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32,\n",
       " torch.Size([3, 3, 3, 3, 3, 3]),\n",
       " 6,\n",
       " tensor([[[[[[7.6469e-01, 7.8510e-01, 2.1175e-02],\n",
       "             [2.2299e-01, 6.5125e-01, 3.9547e-01],\n",
       "             [8.1113e-01, 2.5580e-01, 7.5705e-01]],\n",
       " \n",
       "            [[3.9516e-01, 8.0950e-01, 3.7291e-01],\n",
       "             [3.4508e-01, 2.5110e-01, 4.7198e-01],\n",
       "             [6.6841e-01, 1.9053e-01, 1.4895e-01]],\n",
       " \n",
       "            [[6.7143e-01, 4.7191e-01, 5.0533e-01],\n",
       "             [4.9091e-01, 7.7929e-01, 3.2457e-01],\n",
       "             [1.2489e-01, 1.3912e-01, 5.2219e-01]]],\n",
       " \n",
       " \n",
       "           [[[8.1909e-01, 7.0398e-01, 3.2640e-01],\n",
       "             [8.4172e-02, 5.9629e-01, 4.7422e-01],\n",
       "             [9.0014e-01, 3.3085e-01, 7.6095e-01]],\n",
       " \n",
       "            [[3.2282e-01, 9.6095e-02, 3.0749e-01],\n",
       "             [9.4713e-02, 4.7450e-01, 8.7923e-01],\n",
       "             [4.8798e-01, 7.1430e-01, 7.4669e-01]],\n",
       " \n",
       "            [[2.2591e-01, 4.5535e-01, 5.5081e-01],\n",
       "             [7.9656e-01, 4.5940e-01, 4.0065e-01],\n",
       "             [1.3463e-02, 6.3334e-03, 3.6442e-01]]],\n",
       " \n",
       " \n",
       "           [[[1.8060e-01, 6.2468e-01, 1.9719e-01],\n",
       "             [4.2716e-01, 4.6546e-01, 4.6799e-01],\n",
       "             [7.4093e-02, 9.9095e-01, 4.1521e-01]],\n",
       " \n",
       "            [[2.4186e-01, 3.3051e-01, 5.0169e-01],\n",
       "             [6.6001e-01, 3.1098e-01, 4.8915e-01],\n",
       "             [1.2751e-01, 2.5411e-01, 2.5838e-01]],\n",
       " \n",
       "            [[1.8570e-01, 4.3549e-01, 3.7408e-01],\n",
       "             [4.6409e-01, 7.3689e-02, 4.6153e-01],\n",
       "             [6.5764e-01, 7.5791e-01, 3.6766e-01]]]],\n",
       " \n",
       " \n",
       " \n",
       "          [[[[5.7776e-02, 7.6714e-01, 6.5535e-01],\n",
       "             [1.0908e-01, 2.0696e-01, 1.9488e-01],\n",
       "             [9.2644e-01, 6.0564e-01, 5.7794e-01]],\n",
       " \n",
       "            [[5.1566e-01, 1.5343e-01, 2.4292e-01],\n",
       "             [1.3227e-01, 6.3077e-01, 9.2522e-01],\n",
       "             [6.5450e-01, 4.4594e-01, 8.7799e-01]],\n",
       " \n",
       "            [[9.0907e-01, 8.6188e-01, 1.8711e-01],\n",
       "             [3.4274e-01, 1.5672e-01, 1.1839e-01],\n",
       "             [3.9177e-01, 2.0863e-01, 9.5200e-01]]],\n",
       " \n",
       " \n",
       "           [[[1.4443e-01, 6.1865e-01, 1.0261e-02],\n",
       "             [2.7296e-01, 2.1636e-01, 1.1539e-01],\n",
       "             [9.7054e-02, 6.3121e-02, 8.7211e-01]],\n",
       " \n",
       "            [[5.7183e-01, 7.5246e-01, 4.3173e-01],\n",
       "             [7.5480e-01, 5.0660e-01, 5.5368e-01],\n",
       "             [4.8309e-01, 7.9298e-01, 2.8646e-01]],\n",
       " \n",
       "            [[3.1868e-01, 3.7943e-02, 6.0297e-01],\n",
       "             [5.3082e-01, 6.2306e-01, 7.0301e-01],\n",
       "             [7.1032e-01, 3.8336e-01, 8.6251e-01]]],\n",
       " \n",
       " \n",
       "           [[[9.0577e-01, 6.6277e-01, 1.7036e-01],\n",
       "             [8.4386e-01, 7.4619e-01, 6.3658e-01],\n",
       "             [8.9666e-01, 2.5410e-01, 9.8364e-01]],\n",
       " \n",
       "            [[5.9973e-02, 9.6653e-01, 6.9168e-01],\n",
       "             [4.5575e-01, 5.0543e-01, 8.5902e-01],\n",
       "             [6.6912e-01, 8.9429e-01, 3.0196e-01]],\n",
       " \n",
       "            [[7.7395e-01, 8.4369e-01, 3.4553e-01],\n",
       "             [8.9645e-01, 8.5227e-01, 6.4975e-01],\n",
       "             [7.1101e-01, 6.7872e-01, 6.8665e-01]]]],\n",
       " \n",
       " \n",
       " \n",
       "          [[[[6.1501e-01, 7.9866e-01, 5.8603e-01],\n",
       "             [3.1250e-01, 6.6774e-02, 6.4414e-02],\n",
       "             [5.9809e-01, 4.4198e-01, 2.8921e-01]],\n",
       " \n",
       "            [[3.0132e-01, 8.9722e-01, 4.2320e-01],\n",
       "             [5.7297e-01, 6.1854e-01, 7.4749e-01],\n",
       "             [2.9663e-01, 6.7014e-01, 1.9422e-01]],\n",
       " \n",
       "            [[2.8944e-01, 4.0787e-01, 3.4344e-01],\n",
       "             [8.5830e-01, 3.1812e-01, 7.2675e-01],\n",
       "             [4.4552e-01, 9.4119e-01, 1.5616e-01]]],\n",
       " \n",
       " \n",
       "           [[[4.8170e-01, 3.5404e-01, 9.0890e-01],\n",
       "             [4.9653e-01, 9.1612e-01, 6.4854e-01],\n",
       "             [4.1471e-01, 4.2006e-01, 2.3938e-01]],\n",
       " \n",
       "            [[3.1680e-01, 4.0070e-01, 9.1803e-01],\n",
       "             [8.6836e-01, 9.6201e-02, 4.2717e-01],\n",
       "             [7.9263e-01, 7.2921e-01, 3.4441e-01]],\n",
       " \n",
       "            [[2.5307e-01, 1.6471e-01, 6.9794e-02],\n",
       "             [3.9332e-03, 4.6343e-01, 9.4011e-01],\n",
       "             [4.0762e-01, 4.5642e-01, 4.9627e-01]]],\n",
       " \n",
       " \n",
       "           [[[7.8914e-01, 9.2288e-01, 4.3138e-01],\n",
       "             [2.0934e-01, 2.9438e-01, 4.5490e-02],\n",
       "             [4.3488e-01, 4.3680e-01, 8.4559e-03]],\n",
       " \n",
       "            [[1.5527e-01, 2.9508e-01, 5.6314e-01],\n",
       "             [7.1624e-01, 1.3285e-01, 8.3911e-02],\n",
       "             [9.0305e-01, 9.1417e-01, 9.6266e-01]],\n",
       " \n",
       "            [[5.9325e-01, 4.5065e-01, 3.9114e-01],\n",
       "             [3.1269e-01, 1.8316e-01, 4.8053e-01],\n",
       "             [5.7116e-01, 2.4002e-01, 3.7383e-01]]]]],\n",
       " \n",
       " \n",
       " \n",
       " \n",
       "         [[[[[3.5549e-01, 4.7860e-01, 6.6143e-01],\n",
       "             [9.8799e-01, 7.9623e-01, 4.4050e-01],\n",
       "             [2.6762e-01, 7.0346e-01, 8.9976e-01]],\n",
       " \n",
       "            [[6.6967e-01, 9.6072e-01, 6.2595e-01],\n",
       "             [4.2014e-02, 3.3162e-01, 7.3692e-01],\n",
       "             [2.3334e-01, 5.1205e-01, 6.1710e-01]],\n",
       " \n",
       "            [[4.5250e-01, 3.5834e-01, 6.4124e-01],\n",
       "             [9.5936e-01, 2.1954e-01, 2.9407e-01],\n",
       "             [8.3323e-01, 5.8273e-01, 1.9347e-01]]],\n",
       " \n",
       " \n",
       "           [[[3.8546e-01, 4.3793e-01, 9.6485e-01],\n",
       "             [4.9575e-02, 9.6559e-01, 1.2795e-01],\n",
       "             [1.6514e-01, 5.7175e-01, 3.1123e-01]],\n",
       " \n",
       "            [[1.1479e-01, 4.8788e-01, 2.8221e-01],\n",
       "             [2.5447e-01, 3.6439e-01, 1.4578e-01],\n",
       "             [9.4500e-01, 3.4676e-01, 4.7791e-01]],\n",
       " \n",
       "            [[8.4921e-01, 2.3918e-01, 4.6479e-01],\n",
       "             [7.1494e-01, 9.3927e-01, 7.8431e-01],\n",
       "             [3.1147e-01, 4.7585e-01, 5.3466e-01]]],\n",
       " \n",
       " \n",
       "           [[[1.8372e-02, 8.6265e-02, 5.0396e-01],\n",
       "             [2.3206e-01, 6.8445e-01, 9.2153e-01],\n",
       "             [2.8552e-01, 6.6762e-01, 6.2807e-01]],\n",
       " \n",
       "            [[5.0435e-02, 8.4251e-01, 2.5738e-01],\n",
       "             [4.4578e-01, 8.5444e-02, 8.3715e-01],\n",
       "             [1.0382e-01, 8.5333e-01, 5.5390e-01]],\n",
       " \n",
       "            [[2.8605e-01, 3.7763e-01, 5.8412e-02],\n",
       "             [3.9470e-04, 9.4000e-01, 3.6262e-01],\n",
       "             [1.5825e-01, 4.5926e-01, 1.2596e-01]]]],\n",
       " \n",
       " \n",
       " \n",
       "          [[[[6.7344e-01, 4.3848e-01, 2.9604e-01],\n",
       "             [6.8468e-01, 8.1672e-01, 3.3352e-01],\n",
       "             [1.3383e-01, 2.3536e-01, 2.3145e-01]],\n",
       " \n",
       "            [[3.3419e-01, 4.6630e-01, 1.0931e-01],\n",
       "             [8.5633e-01, 8.0807e-01, 7.1036e-01],\n",
       "             [1.7939e-01, 3.3625e-01, 2.8874e-01]],\n",
       " \n",
       "            [[1.3234e-02, 2.9954e-01, 1.3125e-01],\n",
       "             [3.0441e-01, 5.7170e-01, 5.6701e-01],\n",
       "             [4.9493e-01, 4.7529e-01, 3.5126e-01]]],\n",
       " \n",
       " \n",
       "           [[[7.9027e-01, 4.6747e-01, 6.3031e-01],\n",
       "             [9.4102e-01, 6.2816e-01, 1.6180e-02],\n",
       "             [5.2364e-01, 5.3432e-01, 4.7376e-01]],\n",
       " \n",
       "            [[5.6945e-01, 3.0564e-01, 3.3078e-01],\n",
       "             [4.6566e-01, 3.7529e-01, 6.4015e-01],\n",
       "             [3.9702e-01, 5.2449e-01, 1.6739e-01]],\n",
       " \n",
       "            [[8.5015e-01, 4.1830e-02, 2.2175e-01],\n",
       "             [4.3318e-01, 3.5614e-01, 2.2714e-01],\n",
       "             [3.3815e-01, 5.5220e-01, 8.2546e-01]]],\n",
       " \n",
       " \n",
       "           [[[2.6687e-01, 4.8456e-01, 7.5649e-01],\n",
       "             [8.1789e-01, 1.4752e-02, 7.1555e-01],\n",
       "             [1.2209e-01, 7.1360e-01, 2.7099e-01]],\n",
       " \n",
       "            [[2.8307e-01, 6.0794e-01, 1.4551e-01],\n",
       "             [4.6915e-02, 7.3319e-01, 1.2200e-01],\n",
       "             [2.2159e-02, 2.6564e-02, 5.9837e-01]],\n",
       " \n",
       "            [[8.5061e-01, 5.3840e-01, 4.0155e-01],\n",
       "             [7.7412e-01, 5.8493e-01, 6.7914e-01],\n",
       "             [3.7547e-01, 9.1157e-01, 3.7139e-01]]]],\n",
       " \n",
       " \n",
       " \n",
       "          [[[[5.4856e-01, 7.0981e-02, 7.9000e-01],\n",
       "             [7.4343e-01, 4.8418e-01, 8.5741e-01],\n",
       "             [2.8981e-01, 3.2981e-01, 7.7104e-01]],\n",
       " \n",
       "            [[4.8463e-01, 4.1645e-02, 6.3086e-01],\n",
       "             [1.7285e-01, 7.6978e-01, 5.2392e-01],\n",
       "             [8.3671e-02, 3.7145e-01, 7.0877e-02]],\n",
       " \n",
       "            [[3.8632e-01, 4.9742e-01, 9.2393e-01],\n",
       "             [3.3123e-01, 1.8142e-01, 4.1571e-01],\n",
       "             [8.8481e-01, 7.3077e-01, 6.5775e-01]]],\n",
       " \n",
       " \n",
       "           [[[2.2159e-01, 6.2436e-01, 4.1516e-01],\n",
       "             [3.6802e-01, 9.1472e-02, 9.8434e-01],\n",
       "             [1.7082e-01, 2.4067e-01, 1.1937e-01]],\n",
       " \n",
       "            [[9.3815e-01, 5.8985e-01, 8.2358e-01],\n",
       "             [7.8324e-01, 9.5046e-02, 4.4834e-01],\n",
       "             [7.6981e-01, 3.8918e-01, 9.4982e-01]],\n",
       " \n",
       "            [[3.4251e-01, 3.1123e-01, 7.7477e-01],\n",
       "             [8.6503e-01, 1.7707e-01, 3.6442e-01],\n",
       "             [6.7267e-01, 8.6901e-01, 3.1579e-01]]],\n",
       " \n",
       " \n",
       "           [[[4.8348e-01, 2.0646e-01, 1.4954e-01],\n",
       "             [9.9505e-01, 1.0459e-01, 6.1245e-01],\n",
       "             [2.0290e-01, 3.5398e-01, 4.7850e-01]],\n",
       " \n",
       "            [[4.6810e-01, 1.8337e-01, 5.8640e-01],\n",
       "             [3.1872e-01, 6.9922e-01, 8.5660e-01],\n",
       "             [8.8662e-01, 9.6187e-02, 1.9122e-01]],\n",
       " \n",
       "            [[1.2202e-01, 7.8297e-01, 7.4003e-01],\n",
       "             [1.0903e-01, 9.4326e-01, 9.4287e-01],\n",
       "             [6.4782e-01, 7.7772e-01, 9.1299e-02]]]]],\n",
       " \n",
       " \n",
       " \n",
       " \n",
       "         [[[[[7.9368e-01, 9.7209e-02, 5.4696e-01],\n",
       "             [3.3596e-01, 3.9064e-01, 9.2346e-01],\n",
       "             [5.5065e-01, 1.6960e-02, 2.5797e-01]],\n",
       " \n",
       "            [[8.4714e-01, 1.3235e-01, 2.8531e-01],\n",
       "             [6.7974e-01, 7.9437e-01, 6.8614e-01],\n",
       "             [8.7209e-01, 9.0995e-01, 7.1983e-01]],\n",
       " \n",
       "            [[2.5925e-01, 5.4048e-01, 7.7654e-01],\n",
       "             [9.5422e-01, 1.4212e-01, 7.1834e-01],\n",
       "             [6.8096e-01, 7.9718e-01, 5.4535e-01]]],\n",
       " \n",
       " \n",
       "           [[[6.2240e-01, 6.1406e-01, 9.1861e-01],\n",
       "             [5.0582e-02, 1.1539e-01, 3.5163e-01],\n",
       "             [9.6591e-01, 7.7915e-01, 4.1581e-01]],\n",
       " \n",
       "            [[1.0531e-01, 2.1874e-01, 8.8520e-01],\n",
       "             [7.4491e-01, 6.0989e-01, 6.7115e-01],\n",
       "             [1.7365e-01, 7.5971e-01, 9.1154e-01]],\n",
       " \n",
       "            [[3.2445e-01, 2.3253e-01, 2.6340e-01],\n",
       "             [3.8964e-01, 8.0203e-01, 7.0265e-01],\n",
       "             [6.5608e-01, 9.5109e-01, 7.1844e-01]]],\n",
       " \n",
       " \n",
       "           [[[3.2590e-01, 8.8256e-01, 1.0972e-01],\n",
       "             [9.0402e-01, 8.3448e-01, 7.5354e-01],\n",
       "             [5.6869e-01, 2.0246e-01, 6.0300e-01]],\n",
       " \n",
       "            [[5.1225e-01, 3.4326e-01, 6.8838e-01],\n",
       "             [2.6944e-01, 2.3839e-01, 2.8687e-01],\n",
       "             [4.9564e-02, 2.5456e-01, 7.2829e-01]],\n",
       " \n",
       "            [[1.0075e-01, 5.0191e-01, 1.0753e-01],\n",
       "             [8.5032e-01, 2.4316e-01, 2.1889e-01],\n",
       "             [5.9764e-01, 5.4849e-01, 3.1869e-01]]]],\n",
       " \n",
       " \n",
       " \n",
       "          [[[[3.6471e-01, 1.9827e-01, 1.7498e-01],\n",
       "             [3.5600e-01, 5.7306e-02, 5.2425e-01],\n",
       "             [7.8497e-01, 9.9008e-01, 2.1721e-01]],\n",
       " \n",
       "            [[5.6987e-01, 9.4744e-01, 6.5185e-01],\n",
       "             [1.7614e-01, 8.9785e-01, 9.2565e-02],\n",
       "             [7.9519e-03, 6.8749e-01, 6.6106e-01]],\n",
       " \n",
       "            [[8.0409e-01, 1.1782e-01, 1.3923e-01],\n",
       "             [4.5983e-01, 9.3526e-01, 2.5100e-01],\n",
       "             [2.0348e-02, 7.1909e-01, 9.7334e-01]]],\n",
       " \n",
       " \n",
       "           [[[9.3790e-01, 8.8944e-01, 5.6981e-01],\n",
       "             [5.6213e-01, 6.3487e-01, 9.8651e-01],\n",
       "             [7.5511e-01, 9.3583e-01, 4.2398e-01]],\n",
       " \n",
       "            [[7.5872e-01, 3.6347e-02, 1.9162e-01],\n",
       "             [2.9752e-01, 4.3878e-01, 8.8009e-01],\n",
       "             [5.2671e-02, 5.8059e-01, 7.2696e-01]],\n",
       " \n",
       "            [[1.6552e-01, 9.5327e-01, 2.3179e-01],\n",
       "             [3.0603e-02, 5.5306e-01, 3.7268e-01],\n",
       "             [7.9984e-01, 7.7092e-01, 5.4593e-02]]],\n",
       " \n",
       " \n",
       "           [[[8.7335e-01, 9.1730e-01, 6.3313e-01],\n",
       "             [5.2856e-01, 2.1470e-01, 9.7362e-01],\n",
       "             [2.1127e-01, 3.6367e-01, 5.2883e-01]],\n",
       " \n",
       "            [[5.6714e-01, 7.5829e-01, 9.5019e-01],\n",
       "             [5.5579e-01, 6.6487e-01, 7.0640e-01],\n",
       "             [9.9428e-01, 2.8061e-02, 6.3905e-02]],\n",
       " \n",
       "            [[7.2363e-01, 5.0427e-01, 3.0272e-01],\n",
       "             [7.4501e-01, 9.6445e-02, 8.9505e-01],\n",
       "             [9.6583e-01, 4.3124e-01, 2.2702e-01]]]],\n",
       " \n",
       " \n",
       " \n",
       "          [[[[4.8218e-01, 9.0669e-01, 2.8309e-01],\n",
       "             [6.7350e-01, 5.3660e-02, 4.7294e-02],\n",
       "             [2.4013e-01, 8.8196e-01, 9.4389e-01]],\n",
       " \n",
       "            [[7.1560e-01, 1.3613e-01, 3.7841e-01],\n",
       "             [4.2939e-01, 1.4343e-01, 2.9755e-01],\n",
       "             [2.1166e-01, 1.8599e-01, 9.4931e-01]],\n",
       " \n",
       "            [[9.8450e-01, 8.4596e-01, 8.5669e-02],\n",
       "             [4.7274e-01, 3.6919e-01, 8.8082e-01],\n",
       "             [7.2386e-01, 9.1689e-01, 4.8784e-01]]],\n",
       " \n",
       " \n",
       "           [[[9.0964e-01, 7.4297e-01, 7.6782e-01],\n",
       "             [9.3109e-01, 8.2148e-02, 6.8741e-01],\n",
       "             [1.1629e-01, 6.8250e-01, 5.8813e-01]],\n",
       " \n",
       "            [[6.1577e-01, 2.7318e-01, 2.3844e-01],\n",
       "             [9.7189e-01, 6.5766e-01, 9.7445e-01],\n",
       "             [5.7526e-01, 7.9203e-01, 6.9937e-01]],\n",
       " \n",
       "            [[3.5996e-01, 9.9860e-01, 1.6773e-01],\n",
       "             [8.5462e-01, 9.2275e-01, 5.7614e-01],\n",
       "             [9.1881e-01, 1.0888e-01, 6.3670e-01]]],\n",
       " \n",
       " \n",
       "           [[[5.1861e-01, 9.3236e-01, 3.6904e-02],\n",
       "             [6.4370e-01, 4.6868e-01, 6.6266e-01],\n",
       "             [5.1057e-01, 1.9011e-01, 1.7798e-01]],\n",
       " \n",
       "            [[5.3566e-01, 2.2686e-01, 6.9717e-01],\n",
       "             [9.7683e-01, 7.5543e-01, 9.1582e-01],\n",
       "             [9.5858e-01, 8.3453e-01, 6.7742e-01]],\n",
       " \n",
       "            [[5.8065e-01, 6.7324e-01, 3.5618e-01],\n",
       "             [1.6840e-01, 1.5441e-01, 2.9741e-01],\n",
       "             [6.9324e-02, 7.0007e-01, 2.8135e-01]]]]]]))"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of 4dim:\n",
    "random_tensor_4d = torch.rand(size=(3, 3, 3, 3))\n",
    "random_tensor_4d.dtype, random_tensor.shape, random_tensor.ndim, random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "99b70896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 3])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (224, 224, 3)\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "random_image_size_tensor.shape\n",
    "random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4c0843c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 3])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In torch, '.size()' essentially does the same thing as '.shape' ; \n",
    "random_image_size_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ff13e9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros.dtype\n",
    "zeros.size()\n",
    "zeros.ndim\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "3848c35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 3, 3))\n",
    "ones.dtype\n",
    "ones.size()\n",
    "ones.ndim\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "57ea10cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreating a range and tensors like\\nSometimes you might want a range of numbers, such as 1 to 10 or 0 to 100.\\n\\nYou can use torch.arange(start, end, step) to do so.\\n\\nWhere:\\n\\nstart = start of range (e.g. 0)\\nend = end of range (e.g. 10)\\nstep = how many steps in between each value (e.g. 1)\\nNote: In Python, you can use range() to create a range. However in PyTorch, torch.range() is deprecated and may show an error in the future.\\n'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creating a range and tensors like\n",
    "Sometimes you might want a range of numbers, such as 1 to 10 or 0 to 100.\n",
    "\n",
    "You can use torch.arange(start, end, step) to do so.\n",
    "\n",
    "Where:\n",
    "\n",
    "start = start of range (e.g. 0)\n",
    "end = end of range (e.g. 10)\n",
    "step = how many steps in between each value (e.g. 1)\n",
    "Note: In Python, you can use range() to create a range. However in PyTorch, torch.range() is deprecated and may show an error in the future.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "784277ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange(), torch.range() is deprecated \n",
    "zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n",
    "\n",
    "# Create a range of values 0 to 10\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten.shape\n",
    "zero_to_ten.ndim\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "12bc4581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also create a tensor of zeros similar to another tensor\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten) # will have same shape\n",
    "ten_zeros.shape\n",
    "ten_zeros.ndim\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794899a",
   "metadata": {},
   "source": [
    "### Tensor datatypes\n",
    "\n",
    "There are many different [tensor datatypes available in PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "\n",
    "Some are specific for CPU and some are better for GPU.\n",
    "\n",
    "Getting to know which one can take some time.\n",
    "\n",
    "Generally if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).\n",
    "\n",
    "The most common type (and generally the default) is `torch.float32` or `torch.float`.\n",
    "\n",
    "This is referred to as \"32-bit floating point\".\n",
    "\n",
    "But there's also 16-bit floating point (`torch.float16` or `torch.half`) and 64-bit floating point (`torch.float64` or `torch.double`).\n",
    "\n",
    "And to confuse things even more there's also 8-bit, 16-bit, 32-bit and 64-bit integers.\n",
    "\n",
    "Plus more!\n",
    "\n",
    "> **Note:** An integer is a flat round number like `7` whereas a float has a decimal `7.0`.\n",
    "\n",
    "The reason for all of these is to do with **precision in computing**.\n",
    "\n",
    "Precision is the amount of detail used to describe a number.\n",
    "\n",
    "The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
    "\n",
    "This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use.\n",
    "\n",
    "So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate).\n",
    "\n",
    "> **Resources:** \n",
    "  * See the [PyTorch documentation for a list of all available tensor datatypes](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "  * Read the [Wikipedia page for an overview of what precision in computing](https://en.wikipedia.org/wiki/Precision_(computer_science)) is.\n",
    "\n",
    "Let's see how to create some tensors with specific datatypes. We can do so using the `dtype` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8ca305d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or w/e dtype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bfb3b4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float16) # torch.half would also work\n",
    "\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1e1c4d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchHalf_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.half) # torch.half would also work\n",
    "\n",
    "torchHalf_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "27771f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_64_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float64) # torch.double would also work (for float64)\n",
    "\n",
    "float_64_tensor.dtype\n",
    "\n",
    "double_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.double)\n",
    "double_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e44a9",
   "metadata": {},
   "source": [
    "## Getting information from tensors\n",
    "\n",
    "Once you've created tensors (or someone else or a PyTorch module has created them for you), you might want to get some information from them.\n",
    "\n",
    "We've seen these before but three of the most common attributes you'll want to find out about tensors are:\n",
    "* `shape` - what shape is the tensor? (some operations require specific shape rules)\n",
    "* `dtype` - what datatype are the elements within the tensor stored in?\n",
    "* `device` - what device is the tensor stored on? (usually GPU or CPU)\n",
    "\n",
    "Let's create a random tensor and find out details about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "6c9a8204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.03 ms, sys: 2.93 ms, total: 3.96 ms\n",
      "Wall time: 2.91 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d69613",
   "metadata": {},
   "source": [
    "One of the most common errors in deep learning (shape errors)\n",
    "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most common errors you'll run into in deep learning is shape mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "542d74a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor(\n",
    "    [[1, 2],\n",
    "     [3, 4],\n",
    "     [5, 6]]\n",
    "    , dtype=torch.float32\n",
    ")\n",
    "\n",
    "tensor_B = torch.tensor(\n",
    "    [[7, 10],     \n",
    "     [8, 11],      \n",
    "     [9, 12]]\n",
    "    , dtype=torch.float32\n",
    ")\n",
    "\n",
    "tensor_A.shape\n",
    "tensor_A.ndim\n",
    "\n",
    "tensor_B.shape\n",
    "tensor_B.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "70ee29dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A\n",
    "tensor_A.ndim\n",
    "torch.argmax(tensor_A, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0a7278dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A\n",
    "tensor_A.ndim\n",
    "torch.argmin(tensor_A, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "0d17ec26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "argmax:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[2],\n",
       "         [2],\n",
       "         [2]]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "argmin:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0],\n",
       "         [0],\n",
       "         [0]]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d\n",
    "tensor3d.ndim\n",
    "print('\\nargmax:')\n",
    "torch.argmax(tensor3d, dim=2, keepdim=True)\n",
    "torch.argmax(tensor3d, dim=2, keepdim=False)\n",
    "# torch.argmax(tensor3d, dim=2, keepdim=True)\n",
    "\n",
    "print('\\nargmin:')\n",
    "torch.argmin(tensor3d, dim=2, keepdim=True)\n",
    "torch.argmin(tensor3d, dim=2, keepdim=False)\n",
    "# torch.argmin(tensor3d, dim=2, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b402ce22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "outputs = torch.tensor([[0.1, 0.7, 0.2], [0.3, 0.4, 0.3]])\n",
    "predictions = torch.argmax(outputs, dim=1)\n",
    "print(\"Predicted classes:\", predictions)  # Output: tensor([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f61138a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "outputs = torch.tensor([[0.1, 0.7, 0.2], [0.3, 0.4, 0.3]])\n",
    "predictions_ = torch.argmin(outputs, dim=1)\n",
    "print(\"Predicted classes:\", predictions_)  # Output: tensor([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "7b42bde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.7000, 0.2000],\n",
       "        [0.3000, 0.4000, 0.3000]])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4000)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1000)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs\n",
    "outputs.ndim\n",
    "outputs.shape\n",
    "outputs[1,1]\n",
    "torch.argmax(outputs, dim=1)\n",
    "outputs[0,0]\n",
    "torch.argmin(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "08792138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dimension 0: 2\n",
      "Size of dimension 1: 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "my_tensor = torch.randn(2, 3, 4)  # Example tensor with shape (2, 3, 4)\n",
    "\n",
    "# Get the size of the first dimension (index 0)\n",
    "dim_0_size = my_tensor.size(0)\n",
    "print(f\"Size of dimension 0: {dim_0_size}\")\n",
    "\n",
    "# Get the size of the second dimension (index 1)\n",
    "dim_1_size = my_tensor.size(1)\n",
    "print(f\"Size of dimension 1: {dim_1_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1b198fcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[233], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmatmul(tensor_A, tensor_B)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "torch.matmul(tensor_A, tensor_B) # (this will error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d01d059",
   "metadata": {},
   "source": [
    "We can make matrix multiplication work between `tensor_A` and `tensor_B` by making their inner dimensions match.\n",
    "\n",
    "One of the ways to do this is with a **transpose** (switch the dimensions of a given tensor).\n",
    "\n",
    "You can perform transposes in PyTorch using either:\n",
    "* `torch.transpose(input, dim0, dim1)` - where `input` is the desired tensor to transpose and `dim0` and `dim1` are the dimensions to be swapped.\n",
    "* `tensor.T` - where `tensor` is the desired tensor to transpose.\n",
    "\n",
    "Let's try the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b08f659b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7., 10.],\n",
      "        [ 8., 11.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B\n",
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "733e7971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B.T\n",
    "print(tensor_A)\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "aba85ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape\n",
    "tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "74c00fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mm is a shortcut for matmul\n",
    "# If you Transpose (.T) one of these to get the inner dims to match, you will have a successful mm!\n",
    "\n",
    "torch.mm(tensor_A, tensor_B.T)\n",
    "\n",
    "torch.mm(tensor_A, tensor_B.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "bbdf626e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5207, 1.1566, 1.1057, 0.7964, 1.3520, 0.8454, 0.4781, 0.7543],\n",
       "        [1.1264, 0.9972, 0.8675, 0.9049, 0.9479, 0.5577, 0.1958, 0.6947],\n",
       "        [1.3099, 1.0086, 1.0283, 1.0125, 1.1383, 0.6042, 0.3941, 0.6855],\n",
       "        [0.8973, 0.8315, 0.5420, 0.1281, 0.7900, 0.6931, 0.1229, 0.5353]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(torch.rand(4,3),torch.rand(3,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0583e8f9",
   "metadata": {},
   "source": [
    "### MATRIX MULTIPLICATION RULES: ###\n",
    "\n",
    "*There are two (2) main rules that performing matrix multiplication (matmul; mm;) must satisfy:\n",
    "\n",
    "1. The **inner dimensions** must match:\n",
    "*e.g.,*\n",
    "\n",
    "    **(2, 3) @ (2, 3) :** `torch.mm(torch.rand(2, 3), torch.rand(2, 3))` will *NOT* work\n",
    "    \n",
    "    **(3, 2) @ (2, 3) :** `torch.mm(torch.rand(3, 2), torch.rand(2, 3))` *WILL* work\n",
    "    \n",
    "    **(2, 3) @ (3, 2) :**`torch.mm(torch.rand(2, 3), torch.rand(3, 2))` *WILL* work\n",
    "    \n",
    "    **(2, 3) @ (2, 3).T :** `torch.mm(torch.rand(2, 3), torch.rand(2, 3).T)` *WILL* work\n",
    "    \n",
    "    \n",
    "2. The resulting matrix takes the shape of the **outer dimensions**:\n",
    "\n",
    "    A torch.mm of `(2, 3) @ (3, 2)` becomes --> `(2, 2)` matrix;\n",
    "    \n",
    "    A torch.mm of `(2, 3) @ (3, 2)` becomes --> `(3, 3)` matrix;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "fcd10235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3637, 0.5796],\n",
       "        [1.9189, 0.4409]])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.3230, 0.7292],\n",
       "        [0.6701, 0.6735]])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(torch.rand(2, 3), torch.rand(2, 3).T)\n",
    "torch.mm(torch.rand(2, 3), torch.rand(3, 2))\n",
    "# torch.mm(torch.rand(8, 2).T, torch.rand(2, 8).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "327c1a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1404, 0.4817, 0.6317, 0.6922, 0.3690, 0.8632, 0.7127, 0.5484],\n",
       "        [0.1574, 0.4358, 0.5791, 0.6682, 0.3512, 0.8006, 0.7377, 0.5034],\n",
       "        [0.0677, 0.0662, 0.0989, 0.1619, 0.0784, 0.1499, 0.2460, 0.0870],\n",
       "        [0.2099, 0.3628, 0.5017, 0.6648, 0.3374, 0.7173, 0.8551, 0.4379],\n",
       "        [0.3152, 0.2431, 0.3796, 0.6860, 0.3259, 0.5932, 1.1066, 0.3350],\n",
       "        [0.3200, 0.5341, 0.7414, 0.9940, 0.5031, 1.0631, 1.2928, 0.6473],\n",
       "        [0.2550, 0.1481, 0.2470, 0.5048, 0.2346, 0.4021, 0.8668, 0.2192],\n",
       "        [0.1121, 0.4266, 0.5564, 0.5961, 0.3198, 0.7566, 0.5937, 0.4827]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.4328, 1.3668],\n",
       "        [2.2726, 1.4400]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(torch.rand(8, 2), torch.rand(2, 8))\n",
    "\n",
    "torch.mm(torch.rand(8, 2).T, torch.rand(2, 8).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "f27d9348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.9439, 1.8785, 2.6534],\n",
       "        [2.9305, 2.4667, 3.0990],\n",
       "        [2.3711, 1.3551, 2.6516]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.2315, 0.9617, 1.7230, 0.9464, 0.5783, 0.8605, 0.9849, 0.5666, 1.4884],\n",
       "        [0.9117, 0.6669, 0.9276, 0.4672, 0.3522, 0.6679, 0.5124, 0.4061, 1.0087],\n",
       "        [1.0746, 0.7332, 1.2524, 0.8700, 0.5566, 0.7833, 0.9793, 0.3735, 1.0575],\n",
       "        [0.7848, 0.6636, 1.2435, 0.6083, 0.3539, 0.5310, 0.5981, 0.4150, 1.0631],\n",
       "        [1.4968, 1.0533, 1.7988, 1.1756, 0.7506, 1.0827, 1.3034, 0.5603, 1.5470],\n",
       "        [0.7344, 0.4199, 0.4833, 0.4398, 0.3468, 0.5729, 0.5609, 0.1911, 0.5449],\n",
       "        [0.7284, 0.6572, 1.2144, 0.5078, 0.2929, 0.4829, 0.4665, 0.4383, 1.0823],\n",
       "        [0.9163, 0.4809, 0.5268, 0.5936, 0.4643, 0.7261, 0.7770, 0.1853, 0.5810],\n",
       "        [0.5478, 0.3639, 0.5665, 0.3967, 0.2688, 0.4057, 0.4564, 0.1868, 0.5185]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2268, 0.7719, 0.6393, 1.2911, 0.4146, 1.2605, 0.6757, 1.1610, 0.9811],\n",
       "        [0.2622, 0.8879, 0.8279, 1.4990, 0.4989, 1.4542, 0.7794, 1.3502, 1.1781],\n",
       "        [0.3191, 0.9754, 1.1400, 1.6346, 0.6996, 1.6232, 0.9678, 1.4681, 1.2559],\n",
       "        [0.1563, 0.4089, 0.3953, 0.6333, 0.3554, 0.6890, 0.4938, 0.5580, 0.3447],\n",
       "        [0.1348, 0.4092, 0.1804, 0.6324, 0.2403, 0.6695, 0.4185, 0.5585, 0.3371],\n",
       "        [0.3068, 0.8121, 1.0404, 1.3082, 0.7421, 1.3769, 0.9597, 1.1625, 0.8632],\n",
       "        [0.2362, 0.7021, 0.9188, 1.1829, 0.5447, 1.1758, 0.7185, 1.0630, 0.9270],\n",
       "        [0.1422, 0.5724, 0.6368, 1.0292, 0.2482, 0.9275, 0.3971, 0.9399, 0.9793],\n",
       "        [0.2606, 0.7402, 0.9814, 1.2299, 0.6166, 1.2461, 0.8010, 1.1014, 0.9181]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(torch.rand(3, 9), torch.rand(9, 3))\n",
    "\n",
    "torch.mm(torch.rand(3, 9).T, torch.rand(9, 3).T)\n",
    "torch.mm(torch.rand(9, 3), torch.rand(3, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "15eda9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.mm(torch.rand(3, 9), torch.rand(9, 3))\n",
    "b = torch.mm(torch.rand(3, 9).T, torch.rand(9, 3).T)\n",
    "c = torch.mm(torch.rand(9, 3), torch.rand(3, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "f1f6835a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3.3491, 3.2741, 2.4769],\n",
       "        [3.0355, 2.6182, 2.4291],\n",
       "        [2.0431, 2.4009, 1.7640]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------\n",
      "max\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.3491)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------\n",
      "min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.7640)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ndim\n",
    "a.shape\n",
    "# a[1,1]\n",
    "a\n",
    "print('\\n--------------------------')\n",
    "print('max')\n",
    "torch.max(a)\n",
    "torch.argmax(a, dim=1)\n",
    "\n",
    "print('\\n--------------------------')\n",
    "print('min')\n",
    "torch.min(a)\n",
    "torch.argmin(a, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "b84b489d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ndim\n",
    "b.ndim\n",
    "c.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f2007327",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x4 and 3x4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[271], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# If the inner dimensions DON'T match (e.g. `(3, 4) @ (3, 4)`), you will get a 'shape error':\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m torch\u001b[38;5;241m.\u001b[39mmm(torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m), torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x4 and 3x4)"
     ]
    }
   ],
   "source": [
    "# If the inner dimensions DON'T match (e.g. `(3, 4) @ (3, 4)`), you will get a 'shape error':\n",
    "\n",
    "torch.mm(torch.rand(3, 4), torch.rand(3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b1cda4",
   "metadata": {},
   "source": [
    "### NOTE: SHAPE ERRORS (^^^) ARE ONE OF THE MOST COMMON ERRORS IN DL / NN!!! ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3ca00dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.,  8.,  9.],\n",
       "        [10., 11., 12.]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape\n",
    "tensor_A\n",
    "\n",
    "tensor_B.T.shape\n",
    "tensor_B.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42fb55c",
   "metadata": {},
   "source": [
    "### torch.nn.Linear() ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860a282f",
   "metadata": {},
   "source": [
    "Neural networks are full of matrix multiplications and dot products.\n",
    "\n",
    "The [`torch.nn.Linear()`](https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html) module (we'll see this in action later on), also known as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input `x` and a weights matrix `A`.\n",
    "\n",
    "$$\n",
    "y = x\\cdot{A^T} + b\n",
    "$$\n",
    "\n",
    "Where:\n",
    "* `x` is the input to the layer (deep learning is a stack of layers like `torch.nn.Linear()` and others on top of each other).\n",
    "* `A` is the weights matrix created by the layer, this starts out as random numbers that get adjusted as a neural network learns to better represent patterns in the data (notice the \"`T`\", that's because the weights matrix gets transposed).\n",
    "  * **Note:** You might also often see `W` or another letter like `X` used to showcase the weights matrix.\n",
    "* `b` is the bias term used to slightly offset the weights and inputs.\n",
    "* `y` is the output (a manipulation of the input in the hopes to discover patterns in it).\n",
    "\n",
    "This is a linear function (you may have seen something like $y = mx+b$ in high school or elsewhere), and can be used to draw a straight line!\n",
    "\n",
    "Let's play around with a linear layer.\n",
    "\n",
    "Try changing the values of `in_features` and `out_features` below and see what happens.\n",
    "\n",
    "Do you notice anything to do with the shapes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3bbc7a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input \n",
    "                         out_features=6) # out_features = describes outer value \n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "19d1af53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x132ba5830>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[-0.2647, -0.1677,  0.7681, -0.4541, -0.7028, -0.6111],\n",
      "        [-0.0671, -0.8661,  0.9346, -1.4063, -2.4837, -0.5289],\n",
      "        [ 0.1305, -1.5645,  1.1011, -2.3585, -4.2646, -0.4468]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(27)\n",
    "\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2 # in_features = matches inner dimension of input \n",
    "                         , out_features=6) # out_features = describes outer value \n",
    "\n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d1b2ab",
   "metadata": {},
   "source": [
    "### reshaping, stacking, squeezing, and unsqueezing tensors ###\n",
    "\n",
    "\n",
    "- **Reshaping** `.reshape()` : reshapes an input tensor to a defined shape;\n",
    "\n",
    "- **View**: Returns a view of an input tensor of a certain shape but keeps same memory as original tensor;\n",
    "\n",
    "- **Stacking**:combine multiple tensors on top of eachother (vstack) or side-by-side (hstack); \n",
    "\n",
    "- **Squeeze**: removes all `1` dimensions from a tensor;\n",
    "\n",
    "- **Unsqueeze**: adds a `1` dimension to a target tensor;\n",
    "\n",
    "- **Permute**: Return a view of the input with dimensions permuted (swapped) in a certain way;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2a446f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "x0 = torch.arange(1., 10.)\n",
    "x0, x0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9a3fe5",
   "metadata": {},
   "source": [
    ".reshape()\n",
    "\n",
    ".view()\n",
    "\n",
    ".stack\n",
    "\n",
    ".unstack()\n",
    "\n",
    ".squeeze()\n",
    "\n",
    ".unsqueeze()\n",
    "\n",
    ".permute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "ded39f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 4]' is invalid for input of size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[326], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 4]' is invalid for input of size 6"
     ]
    }
   ],
   "source": [
    "torch.arange(6)\n",
    "torch.arange(6).reshape(2, 3)\n",
    "torch.arange(6).reshape(3, 2)\n",
    "torch.arange(6).reshape(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "f6b268e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 4]' is invalid for input of size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[328], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 4]' is invalid for input of size 6"
     ]
    }
   ],
   "source": [
    "torch.arange(6)\n",
    "torch.arange(6).view(2, 3)\n",
    "torch.arange(6).view(3, 2)\n",
    "torch.arange(6).view(2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73fa206",
   "metadata": {},
   "source": [
    "### Reshaping ###\n",
    "\n",
    "`.reshape()` : reshapes an input tensor to a defined shape;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "2d12970a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([9]))"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9]))"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the shape of x ([7]); any reshaping has to align w/ 7;\n",
    "x0, x0.shape\n",
    "\n",
    "x0.reshape(1,9), x0.shape\n",
    "x0.reshape(9,1), x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "98f025e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9]), tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 9]), tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]))"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([9, 1]),\n",
       " tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]))"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0.shape, x0\n",
    "x_reshaped = x0.reshape(1,9)\n",
    "x_reshaped.shape, x_reshaped\n",
    "\n",
    "x_reshaped_ = x0.reshape(9,1)\n",
    "x_reshaped_.shape, x_reshaped_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0aa26d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0.ndim\n",
    "x_reshaped.ndim\n",
    "x_reshaped_.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "0d553c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.]), torch.Size([9]))"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.arange(9.)\n",
    "x1, x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "989ce85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3., 4., 5., 6., 7., 8.]])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [7.],\n",
       "        [8.]])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.],\n",
       "        [6., 7., 8.]])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshapes to dimensions whose product =  torch.shape (in this case, [9]), will work!\n",
    "# e.g., for [9], (1,9); (9,1); (3,3);\n",
    "\n",
    "x1.shape\n",
    "x1.reshape(1,9)\n",
    "x1.reshape(9,1)\n",
    "x1.reshape(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "42440ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]),\n",
       " torch.Size([12]))"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.arange(1., 13.)\n",
    "x2, x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "9f6fe7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [ 7.,  8.,  9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.],\n",
       "        [ 7.,  8.,  9.],\n",
       "        [10., 11., 12.]])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.],\n",
       "        [11., 12.]])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These all work as they are dimensions that whose prod = 12!!!\n",
    "\n",
    "x2.shape\n",
    "x2.reshape(1,12)\n",
    "x2.reshape(2,6)\n",
    "x2.reshape(3,4)\n",
    "x2.reshape(4,3)\n",
    "x2.reshape(6,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "de34ecde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bdce57",
   "metadata": {},
   "source": [
    "### View ### \n",
    "\n",
    "- Returns a view of an input tensor of a certain shape but keeps same memory as original tensor;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "db489061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the VIEW:\n",
    "\n",
    "z = x.view(1, 7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "07d84454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6c308a",
   "metadata": {},
   "source": [
    "### Stacking ### \n",
    "\n",
    "- Combine multiple tensors on top of eachother (vstack) or side-by-side (hstack); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "4527ac45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "0d8ae832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x stacked, dim=0:\n",
      " tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
      "        [5., 2., 3., 4., 5., 6., 7.],\n",
      "        [5., 2., 3., 4., 5., 6., 7.],\n",
      "        [5., 2., 3., 4., 5., 6., 7.]])\n",
      "\n",
      "x stacked, dim=1:\n",
      " tensor([[5., 5., 5., 5.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [7., 7., 7., 7.]])\n",
      "\n",
      "x stacked, dim=-2:\n",
      " tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
      "        [5., 2., 3., 4., 5., 6., 7.],\n",
      "        [5., 2., 3., 4., 5., 6., 7.],\n",
      "        [5., 2., 3., 4., 5., 6., 7.]])\n",
      "\n",
      "x stacked, dim=-1:\n",
      " tensor([[5., 5., 5., 5.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [7., 7., 7., 7.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A few diff ways to stack based on available dims:\n",
    "\n",
    "print(f\"x stacked, dim=0:\\n {torch.stack([x, x, x, x], dim=0)}\\n\") \n",
    "print(f\"x stacked, dim=1:\\n {torch.stack([x, x, x, x], dim=1)}\\n\") \n",
    "print(f\"x stacked, dim=-2:\\n {torch.stack([x, x, x, x], dim=-2)}\\n\") \n",
    "print(f\"x stacked, dim=-1:\\n {torch.stack([x, x, x, x], dim=-1)}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "079918a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x stacked, dim=2: (Doesn't work! (see error msg below!! vvv))\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[311], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print(f\"x stacked, dim=2: (Doesn't work!)\\n {torch.stack([x, x, x, x], dim=2)}\\n\") \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx stacked, dim=2: (Doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt work! (see error msg below!! vvv))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m torch\u001b[38;5;241m.\u001b[39mstack([x, x, x, x], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "# print(f\"x stacked, dim=2: (Doesn't work!)\\n {torch.stack([x, x, x, x], dim=2)}\\n\") \n",
    "print(\"x stacked, dim=2: (Doesn't work! (see error msg below!! vvv))\\n\")\n",
    "torch.stack([x, x, x, x], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "6962610b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 4])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.]])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([x, x, x, x], dim=-2).ndim\n",
    "torch.stack([x, x, x, x], dim=-2).shape\n",
    "torch.stack([x, x, x, x], dim=-2)\n",
    "\n",
    "torch.stack([x, x, x, x], dim=-1).ndim\n",
    "torch.stack([x, x, x, x], dim=-1).shape\n",
    "torch.stack([x, x, x, x], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "50c593f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x stacked, 'vstack'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x stacked, 'hstack'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([28])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([5., 2., 3., 4., 5., 6., 7., 5., 2., 3., 4., 5., 6., 7., 5., 2., 3., 4.,\n",
       "        5., 6., 7., 5., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"x stacked, 'vstack'\")\n",
    "torch.vstack([x, x, x, x]).ndim\n",
    "torch.vstack([x, x, x, x]).shape\n",
    "torch.vstack([x, x, x, x])\n",
    "\n",
    "print(\"\\nx stacked, 'hstack'\")\n",
    "torch.hstack([x, x, x, x]).ndim\n",
    "torch.hstack([x, x, x, x]).shape\n",
    "torch.hstack([x, x, x, x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f87626",
   "metadata": {},
   "source": [
    "### Squeeze ###\n",
    "\n",
    "- Removes all `1` dimensions from a tensor;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "8b1f0702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "9d61733a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Previous shape: torch.Size([1, 9])\n",
      "\n",
      "New tensor: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "New shape: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# squeezing (removes ALL 1-dim)\n",
    "\n",
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimension from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f243b36c",
   "metadata": {},
   "source": [
    "### Unsqueeze ###\n",
    "\n",
    "- Adds a `1` dimension to a target tensor;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f785dfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous shape: torch.Size([9])\n",
      "\n",
      "New tensor (0): tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "New shape (0): torch.Size([1, 9])\n",
      "\n",
      "New tensor (1): tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n",
      "New shape (1): torch.Size([9, 1])\n",
      "\n",
      "New tensor (-2): tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "New shape (-2): torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor (0): {x_unsqueezed}\")\n",
    "print(f\"New shape (0): {x_unsqueezed.shape}\")\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed_1 = x_squeezed.unsqueeze(dim=1)\n",
    "print(f\"\\nNew tensor (1): {x_unsqueezed_1}\")\n",
    "print(f\"New shape (1): {x_unsqueezed_1.shape}\")\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed_neg2 = x_squeezed.unsqueeze(dim=-2)\n",
    "print(f\"\\nNew tensor (-2): {x_unsqueezed_neg2}\")\n",
    "print(f\"New shape (-2): {x_unsqueezed_neg2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "219a401d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0, x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "99cb605d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3., 4., 5., 6., 7., 8.]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_reshaped = x1.reshape(1,9)\n",
    "x1_reshaped.ndim\n",
    "x1_reshaped.shape\n",
    "x1_reshaped\n",
    "\n",
    "x2_reshaped = x2.reshape(3,4)\n",
    "x2_reshaped.ndim\n",
    "x2_reshaped.shape\n",
    "x2_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e46b1a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3., 4., 5., 6., 7., 8.]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 2., 3., 4., 5., 6., 7., 8.]]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.],\n",
       "         [1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.]]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0.]],\n",
       "\n",
       "          [[1.]],\n",
       "\n",
       "          [[2.]],\n",
       "\n",
       "          [[3.]],\n",
       "\n",
       "          [[4.]],\n",
       "\n",
       "          [[5.]],\n",
       "\n",
       "          [[6.]],\n",
       "\n",
       "          [[7.]],\n",
       "\n",
       "          [[8.]]]]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.unsqueeze(dim=-2)\n",
    "x1.unsqueeze(dim=-2).unsqueeze(dim=-2)\n",
    "x1.unsqueeze(dim=-2).unsqueeze(dim=-1)\n",
    "x1.unsqueeze(dim=-2).unsqueeze(dim=-1).unsqueeze(dim=0).unsqueeze(dim=-2)\n",
    "# x1.unsqueeze(dim=-1)\n",
    "# x1.unsqueeze(dim=-0)\n",
    "# x1.unsqueeze(dim=1)\n",
    "# x1.unsqueeze(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d168d7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "607710be",
   "metadata": {},
   "source": [
    "### Permute ### \n",
    "\n",
    "Return a view of the input with dimensions permuted (swapped) in a certain way;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b164f411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4663, 0.7103, 0.0324],\n",
       "         [0.7413, 0.3879, 0.4627],\n",
       "         [0.1435, 0.5354, 0.2402],\n",
       "         ...,\n",
       "         [0.6320, 0.1558, 0.9028],\n",
       "         [0.2423, 0.4286, 0.2671],\n",
       "         [0.6250, 0.0886, 0.1681]],\n",
       "\n",
       "        [[0.6245, 0.8486, 0.7412],\n",
       "         [0.7378, 0.1131, 0.2990],\n",
       "         [0.0753, 0.9572, 0.3327],\n",
       "         ...,\n",
       "         [0.1643, 0.9120, 0.1175],\n",
       "         [0.4538, 0.9585, 0.8763],\n",
       "         [0.3349, 0.8866, 0.2745]],\n",
       "\n",
       "        [[0.3618, 0.1893, 0.2134],\n",
       "         [0.3976, 0.0803, 0.3752],\n",
       "         [0.1955, 0.3861, 0.2603],\n",
       "         ...,\n",
       "         [0.5931, 0.6666, 0.2963],\n",
       "         [0.5073, 0.7287, 0.3908],\n",
       "         [0.3108, 0.4581, 0.1940]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6713, 0.7002, 0.7621],\n",
       "         [0.0671, 0.1152, 0.3901],\n",
       "         [0.1125, 0.7232, 0.2219],\n",
       "         ...,\n",
       "         [0.9155, 0.0071, 0.3680],\n",
       "         [0.5235, 0.9734, 0.4161],\n",
       "         [0.2239, 0.8087, 0.6867]],\n",
       "\n",
       "        [[0.7522, 0.3017, 0.3963],\n",
       "         [0.6594, 0.4685, 0.6846],\n",
       "         [0.4129, 0.4052, 0.9746],\n",
       "         ...,\n",
       "         [0.8291, 0.9526, 0.6994],\n",
       "         [0.0321, 0.6991, 0.6319],\n",
       "         [0.8069, 0.4380, 0.1870]],\n",
       "\n",
       "        [[0.7125, 0.0076, 0.2447],\n",
       "         [0.0031, 0.2889, 0.2814],\n",
       "         [0.8632, 0.0564, 0.3875],\n",
       "         ...,\n",
       "         [0.0146, 0.3700, 0.4347],\n",
       "         [0.3843, 0.1414, 0.7181],\n",
       "         [0.3503, 0.3290, 0.8615]]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(size=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9dad09",
   "metadata": {},
   "source": [
    "### RANDOM SEEDS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b96c441b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor E:\n",
      "tensor([[0.9847, 0.0852, 0.5334, 0.2196],\n",
      "        [0.2617, 0.7972, 0.2088, 0.4545],\n",
      "        [0.1455, 0.2249, 0.7409, 0.2881],\n",
      "        [0.6578, 0.9087, 0.6871, 0.5610]])\n",
      "\n",
      "Tensor F:\n",
      "tensor([[0.9847, 0.0852, 0.5334, 0.2196],\n",
      "        [0.2617, 0.7972, 0.2088, 0.4545],\n",
      "        [0.1455, 0.2249, 0.7409, 0.2881],\n",
      "        [0.6578, 0.9087, 0.6871, 0.5610]])\n",
      "\n",
      "Does Tensor E equal Tensor F? (anywhere)\n"
     ]
    }
   ],
   "source": [
    "# # Set the random seed\n",
    "RANDOM_SEED=27 # try changing this to different values and see what happens to the numbers below\n",
    "\n",
    "torch.manual_seed(seed=RANDOM_SEED) \n",
    "random_tensor_E = torch.rand(4, 4)\n",
    "\n",
    "# Have to reset the seed every time a new rand() is called \n",
    "# Without this, tensor_D would be different to tensor_C \n",
    "torch.random.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
    "random_tensor_F = torch.rand(4, 4)\n",
    "\n",
    "print(f\"Tensor E:\\n{random_tensor_E}\\n\")\n",
    "print(f\"Tensor F:\\n{random_tensor_F}\\n\")\n",
    "print(f\"Does Tensor E equal Tensor F? (anywhere)\")\n",
    "random_tensor_E == random_tensor_F;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "48f75a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x132ba5830>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9847, 0.0852, 0.5334],\n",
       "         [0.2196, 0.2617, 0.7972],\n",
       "         [0.2088, 0.4545, 0.1455]],\n",
       "\n",
       "        [[0.2249, 0.7409, 0.2881],\n",
       "         [0.6578, 0.9087, 0.6871],\n",
       "         [0.5610, 0.9079, 0.2507]]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.random.manual_seed(seed=RANDOM_SEED)\n",
    "torch.rand(2, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3eeccae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x132ba5830>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5668, 0.6469, 0.9893],\n",
       "         [0.6443, 0.3284, 0.8259],\n",
       "         [0.6804, 0.4878, 0.2030]],\n",
       "\n",
       "        [[0.5597, 0.0477, 0.1639],\n",
       "         [0.1536, 0.7448, 0.8719],\n",
       "         [0.5432, 0.9000, 0.5042]]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.random.manual_seed(seed=54)\n",
    "rand_54 = torch.rand(2, 3, 3)\n",
    "rand_54.ndim\n",
    "rand_54.shape\n",
    "rand_54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2d3c387a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x132ba5830>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3, 3])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9847, 0.0852, 0.5334],\n",
       "          [0.2196, 0.2617, 0.7972],\n",
       "          [0.2088, 0.4545, 0.1455]],\n",
       "\n",
       "         [[0.2249, 0.7409, 0.2881],\n",
       "          [0.6578, 0.9087, 0.6871],\n",
       "          [0.5610, 0.9079, 0.2507]],\n",
       "\n",
       "         [[0.7647, 0.7851, 0.0212],\n",
       "          [0.2230, 0.6513, 0.3955],\n",
       "          [0.8111, 0.2558, 0.7570]]],\n",
       "\n",
       "\n",
       "        [[[0.3952, 0.8095, 0.3729],\n",
       "          [0.3451, 0.2511, 0.4720],\n",
       "          [0.6684, 0.1905, 0.1489]],\n",
       "\n",
       "         [[0.6714, 0.4719, 0.5053],\n",
       "          [0.4909, 0.7793, 0.3246],\n",
       "          [0.1249, 0.1391, 0.5222]],\n",
       "\n",
       "         [[0.8191, 0.7040, 0.3264],\n",
       "          [0.0842, 0.5963, 0.4742],\n",
       "          [0.9001, 0.3308, 0.7610]]],\n",
       "\n",
       "\n",
       "        [[[0.3228, 0.0961, 0.3075],\n",
       "          [0.0947, 0.4745, 0.8792],\n",
       "          [0.4880, 0.7143, 0.7467]],\n",
       "\n",
       "         [[0.2259, 0.4553, 0.5508],\n",
       "          [0.7966, 0.4594, 0.4007],\n",
       "          [0.0135, 0.0063, 0.3644]],\n",
       "\n",
       "         [[0.1806, 0.6247, 0.1972],\n",
       "          [0.4272, 0.4655, 0.4680],\n",
       "          [0.0741, 0.9910, 0.4152]]]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.random.manual_seed(seed=RANDOM_SEED)\n",
    "rand_0 = torch.rand(3, 3, 3, 3)\n",
    "\n",
    "rand_0.ndim\n",
    "rand_0.shape\n",
    "rand_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "59750a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x132ba5830>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9631, 0.2687, 0.8175, 0.8067, 0.0898, 0.2513, 0.6707, 0.4108],\n",
       "        [0.6624, 0.1899, 0.5742, 0.5056, 0.1891, 0.2009, 0.4232, 0.2661],\n",
       "        [0.8842, 0.2695, 0.8036, 0.5205, 0.6508, 0.3556, 0.4455, 0.3037],\n",
       "        [0.5583, 0.1686, 0.5038, 0.3436, 0.3724, 0.2161, 0.2928, 0.1967],\n",
       "        [0.3145, 0.0940, 0.2815, 0.2031, 0.1851, 0.1163, 0.1723, 0.1140],\n",
       "        [0.9064, 0.2595, 0.7847, 0.6955, 0.2489, 0.2727, 0.5819, 0.3654],\n",
       "        [1.3343, 0.3974, 1.1909, 0.8755, 0.7495, 0.4856, 0.7420, 0.4883],\n",
       "        [1.0789, 0.3158, 0.9501, 0.7611, 0.4687, 0.3624, 0.6411, 0.4126]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.5157, 1.9445],\n",
       "        [1.3198, 1.8183]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.random.manual_seed(seed=RANDOM_SEED)\n",
    "\n",
    "torch.mm(torch.rand(8, 2), torch.rand(2, 8))\n",
    "\n",
    "torch.mm(torch.rand(8, 2).T, torch.rand(2, 8).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7738d414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x132ba5830>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 3, 6])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9847, 0.0852, 0.5334, 0.2196, 0.2617, 0.7972],\n",
       "          [0.2088, 0.4545, 0.1455, 0.2249, 0.7409, 0.2881],\n",
       "          [0.6578, 0.9087, 0.6871, 0.5610, 0.9079, 0.2507]]],\n",
       "\n",
       "\n",
       "        [[[0.7647, 0.7851, 0.0212, 0.2230, 0.6513, 0.3955],\n",
       "          [0.8111, 0.2558, 0.7570, 0.3952, 0.8095, 0.3729],\n",
       "          [0.3451, 0.2511, 0.4720, 0.6684, 0.1905, 0.1489]]],\n",
       "\n",
       "\n",
       "        [[[0.6714, 0.4719, 0.5053, 0.4909, 0.7793, 0.3246],\n",
       "          [0.1249, 0.1391, 0.5222, 0.8191, 0.7040, 0.3264],\n",
       "          [0.0842, 0.5963, 0.4742, 0.9001, 0.3308, 0.7610]]]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.random.manual_seed(seed=RANDOM_SEED)\n",
    "rand_1 = torch.rand(3, 1, 3, 6)\n",
    "\n",
    "rand_1.ndim\n",
    "rand_1.shape\n",
    "rand_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e572834a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "305967b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b831720d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Apple Silicon GPU\n",
    "import torch\n",
    "torch.backends.mps.is_available() # Note this will print false if you're not running on a Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3ac98517",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # Use NVIDIA GPU (if available)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\" # Use Apple Silicon GPU (if available)\n",
    "else:\n",
    "    device = \"cpu\" # Default to CPU if no GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5bf041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ca69a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc308d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef0c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b03eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
